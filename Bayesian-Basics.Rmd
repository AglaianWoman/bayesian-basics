--- 
title: <span style="font-size:150%; font-variant:small-caps; font-style:italic; ">Bayesian Basics</span>
author:  |
  <div class="title"><span style="font-size:125%; font-variant:small-caps; font-style:normal">Michael Clark</span><br>
  <span style="font-size:75%; margin: 0 auto; font-style:normal">Statistician Lead</span> <br>
  <img src="img/CSCAR_logos/signature-acronym.png" style="width:24%; padding:10px 0;"> <br>
  <img src="img/ARC_logos/ARC-acronym-signature.png" style="width:17%; padding:10px 0;"> </div>
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: 
    bookdown::tufte_html_book: 
      toc: yes
      number_sections: false
      css: [toc.css, ../css/tufte_bookdown/mytufte.css]
      split_by: rmd
always_allow_html: yes
documentclass: book
bibliography: ['packages.bib', 'BayesBasics.bib']
biblio-style: apalike
link-citations: yes
github-repo: m-clark/docs
description: "An introduction to Bayesian data analysis."


# this is for pdf but also to paste into references; tufte style refs at point of citation in margin
nocite: | 
  @kruschke_doing_2010, @gelman_arm, @mcgrayne_theory_2012, @gelmanPardoe2006,
  @gelmanHwangVehtari, @gelmanVehtariWAIC, @mcelreath2016
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment=NA, cache=F, message = F, warning=F, 
                      R.options=list(width=120), fig.align='center')

# automatically create a bib database for R packages
knitr::write_bib(c(.packages(), 'bookdown', 'knitr', 'rmarkdown'), 'packages.bib')
```

```{r echo=FALSE}
library(tufte); library(tidyverse)
```


#  <span style="color:transparent">Home</span>

<!--chapter:end:index.Rmd-->

# Preface

<span class="marginnote">Initial draft posted 2014 Summer.  Recent updates (2016) include major overhaul from pdf to web-based presentation (twice!). The last pdf version I made is [here](http://m-clark.github.io/docs/IntroBayes.pdf) if anyone wants it, however, it will no longer be updated.  You can download the auto-generated (and ugly) pdf for this document [here](https://m-clark.github.io/docs/bayesian/basics/Bayesian_Basics.pdf).</span>
The following serves as a practical and applied introduction to Bayesian estimation methods for the uninitiated. The goal is to provide just enough information in a brief format to allow one to feel comfortable exploring Bayesian data analysis for themselves, assuming they have the requisite context to begin with. The idea is to cover a similar amount of material as one would in part of a standard statistics sequence in various applied disciplines where statistics is being introduced in general.  

After a conceptual introduction, a fully visible by-hand example is provided using the binomial distribution.  After that, the document proceeds to introduce fully Bayesian analysis with the standard linear regression model, as that is the basis for most applied statistics courses and is assumed to be most familiar to the reader.  Model diagnostics, model enhancements, and additional modeling issues are then explored.  Supplemental materials provide more technical detail if desired, and include a maximum likelihood refresher, overview of programming options in Bayesian analysis, the same regression model using BUGS and JAGS, and 'by-hand' code for the model using the Metropolis-Hastings and Hamiltonian Monte Carlo algorithms.


## Prerequisites

Prerequisites include a basic statistical exposure such as what would be covered in typical (probably graduate) *applied* science statistics course. At least some familiarity with R is necessary to follow the code, but that itself is not necessary, and one may go through any number of introductions on the web to acquire enough knowledge in that respect.  However, note that for the examples here, at least part of the code will employ some Bayesian-specific programming language (e.g. Stan primarily, BUGS and JAGS in the appendix).  No attempt is made to teach those languages though, as it would be difficult to do so efficiently in this more conceptually oriented setting.  As such, it is suggested that one follow the code as best they can, and investigate the respective manuals, relevant texts, etc. further on their own.  Between the text and comments within the code it is hoped that what the code is accomplishing will be fairly clear.  However, I also provide a set of notes that can serve as an overview of Stan [here](https://m-clark.github.io/workshops/bayesian/).

This document relies heavily on @gelman_bda, which I highly recommend, if one is ready for it.  Other sources used or particularly pertinent to the material in this document can be found in the [references section](#references) at the end. Some are more introductory, and which might be more suitable depending on the context you bring.



Color coding:

- <span class="emph">emphasis</span>
- <span class="pack">package</span>
- <span class="func">function</span>
- <span class="objclass">object/class</span>
- [link][Prerequisites]

<!--chapter:end:00_preface.Rmd-->

# Introduction

Bayesian analysis is now fairly common in applied work. It is no longer a surprising thing to see it utilized in non-statistical journals, though it is still fresh enough that many researchers feel they have to put 'Bayesian' in the title of their papers when they implement it.  However, to be clear, one doesn't conduct a Bayesian analysis per se.  A Bayesian logistic regression is still just logistic regression.  The *Bayesian* part comes into play with the perspective on probability that one uses to interpret the results, and in how the estimates are arrived at.  

The Bayesian approach itself is very old at this point. Bayes and Laplace started the whole shebang in the 18^th^ and 19^th^ centuries[^evenolder], and even the modern implementation of it has its foundations in the 30s, 40s and 50s of last century[^old]. So while it may still seem somewhat newer to applied researchers, much of the groundwork has long since been hashed out, and there is no more need to justify a Bayesian analysis any more than there is to use the standard maximum likelihood approach[^justify].  While there are perhaps many reasons why the Bayesian approach to analysis did not catch on until relatively recently, perhaps the biggest is simply computational power.  Bayesian analysis requires an iterative and time-consuming approach that simply wasn't viable for most applied researchers until modern computers.  But nowadays, one can conduct such analysis even on their laptop very easily.

The Bayesian approach to data analysis requires a different way of thinking about things, but its implementation can be seen as an extension of traditional approaches. In fact, as we will see later, it incorporates the very likelihood one uses in standard statistical techniques.  The key difference regards the notion of probability, which, while different than Fisherian or frequentist statistics, is actually more akin to how the average Joe thinks about probability.  Furthermore, p-values and intervals will have the interpretation that many applied researchers incorrectly think their current methods provide.  On top of this one gets a very flexible toolbox that can handle many complex analyses.  In short, the reason to engage in Bayesian analysis is that it has a lot to offer and can potentially handle whatever you throw at it.

As we will see shortly, one must also get used to thinking about distributions rather than fixed points.  With Bayesian analysis we are not so much as making guesses about specific values as in the traditional setting, but more so understanding the limits of our knowledge and getting a healthy sense of the uncertainty of those guesses.


## Bayesian Probability

This section will probably be about as formal as this document gets, and will be very minimal even then.  The focus will be on the conceptual understanding though, and subsequently illustrated with a by-hand example in the next section.


### Conditional probability & Bayes theorem

Bayes theorem is illustrated in terms of probability as follows:


$$p(\mathcal{A}|\mathcal{B}) = \frac{p(\mathcal{B}|\mathcal{A})p(\mathcal{A})}{p(\mathcal{B})}$$
  
<span class="marginnote">The denominator reflects the sum of the numerator for *all* values $\mathcal{A}$ might take on. For example:
$$p(\mathcal{A_i}|\mathcal{B}) = \frac{p(\mathcal{B}|\mathcal{A_i})p(\mathcal{A_i})}{p(\mathcal{B}|\mathcal{A_i})p(\mathcal{A_i}) + \dots + p(\mathcal{B}|\mathcal{A_n})p(\mathcal{A_n})}$$</span>
In short, we are attempting to ascertain the conditional probability of $\mathcal{A}$ given $\mathcal{B}$ based on the conditional probability of $\mathcal{B}$ given $\mathcal{A}$ and the respective probabilities of $\mathcal{A}$ and $\mathcal{B}$.  This is perhaps not altogether enlightening in and of itself, so we will frame it in other ways, and for the upcoming depictions we will ignore the denominator.


<span class="marginnote">The $\propto$ means 'proportional to'.</span>
$$p(hypothesis|data) \propto p(data|hypothesis)p(hypothesis)$$ 
  

In the above formulation, we are trying to obtain the probability of an hypothesis given the evidence at hand (data) and our initial (prior) beliefs regarding that hypothesis.  Here we are already able to see at least one key difference between Bayesian and classical statistics. The Bayesian approach provides a probability of the hypothesis given the data, which is something generally highly desirable from a scientific perspective.

Here is yet another way to consider this:


$$posterior \propto likelihood * prior$$


For this depiction let us consider a standard regression coefficient $b$<span class='marginnote'>If we think of y as our outcome and $\Theta$ as our *set* of coefficients that include all the regression coefficents $b$ and $\sigma^2$ variance, i.e. all parameters we need to estimate for the model: $$p(\mathcal{\Theta}|\mathcal{y}) = \frac{p(\mathcal{y}|\mathcal{\Theta})p(\mathcal{\Theta})}{p(\mathcal{y})}$$</span>. Here we have a prior belief about $b$ expressed as a probability distribution.  As a preliminary example we will assume perhaps that the distribution is normal, and is centered on some value $\mu_b$ and with some variance $\sigma_b^2$.  The likelihood here is the exact same one used in classical statistics- if $y$ is our variable of interest, then the likelihood is $p(y|b)$ as in the standard regression approach using maximum likelihood estimation.  What we end up with in the Bayesian context however is not a specific value of $b$ that would make the data most likely, but a probability distribution for $b$ that serves as a weighted combination of the likelihood and prior.  Given that <span class="emph">posterior distribution</span> for $b$, we can then get the mean, median, 95% <span class="emph">credible interval</span>[^credible] and technically a host of other statistics that might be of interest to us.

To summarize conceptually, we have some belief about the state of the world, expressed as a mathematical model (such as the linear model used in regression).  The Bayesian approach provides an updated belief as a weighted combination of prior beliefs regarding that state and the currently available evidence, with the possibility of the current evidence overwhelming prior beliefs, or prior beliefs remaining largely intact in the face of scant evidence.


$$\text{updated belief} = \text{current evidence} * \text{prior belief or evidence}$$


We will make these concepts more concrete in the next section.

[^evenolder]: Bayes theorem possibly [predates](https://en.wikipedia.org/wiki/Nicholas_Saunderson) Bayes by some accounts.

[^old]: Jeffreys, Metropolis etc.

[^justify]: Though some might suggest that the typical practice of hypothesis testing that comes with standard methods would need *more*.

[^credible]: More on this later.

<!--chapter:end:01_intro.Rmd-->

# A Hands-on Example

## Prior, likelihood, & posterior distributions

The following is an attempt to provide a small example to show the connection between prior distribution, likelihood and posterior distribution.  Let's say we want to estimate the probability that a soccer/football player[^football] will score a penalty kick in a shootout.  We will employ the binomial distribution to model this.

Our goal is to estimate a parameter $\theta$, the probability that the random knucklehead from your favorite football team will score the penalty in a overtime shootout.  Let's say that for this match takes 10 shots per team before the game is decided.

In R, we can represent the following data for your team as follows, as well as setup some other things for later.

```{r goaldat}
shots = c('goal','goal','goal','miss','miss',
          'goal','goal','miss','miss','goal')

# convert to numeric, arbitrarily picking goal=1, miss=0
shotsNum = as.numeric(shots=='goal')
N = length(shots)                      # sample size
nGoal = sum(shots=='goal')             # number of shots made
nMiss = sum(shots=='miss')             # number of those miss
```
<span class="marginnote">The fifth shot would have won the game but was taken by Wayne Rooney.</span>

Recall the binomial distribution where we specify the number of trials for a particular observation and the probability of an event. Let's look at the distribution for a couple values for $\theta$ equal to .5 and .85 and $N=10$ observations.  We will repeat this 1000 times.

```{r binomdist, fig.show='hide', echo=-1, results='hold'}
set.seed(1234)
x1 = rbinom(1000, size=10, p=.5)
x2 = rbinom(1000, size=10, p=.85)

mean(x1); hist(x1)
mean(x2); hist(x2)
```

The histograms not shown, but we can see the means are roughly around $N*p$ as we expect with the binomial. 


## Prior

For our current situation, we don't know $\theta$ and are trying to estimate it.  We will start by supplying some possible values. To keep things simple we'll only consider 10 values that fall between 0 and 1. 

```{r binomGoalStart }
theta = seq(from=1/(N+1), to=N/(N+1), length=10)
```

For the Bayesian approach we must choose a <span class="emph">prior distribution</span> representing our initial beliefs about the estimates we might potentially consider.  I provide three possibilities and note that any one of them would work just fine for this situation. We'll go with a triangular distribution, which will put most of the weight toward values around $.5$. While we will talk more about this later, I will go ahead and mention that this is where some specifically have taken issue with Bayesian estimation in the past, because this part of the process is too *subjective* for their tastes.  Setting aside the fact that subjectivity is an inherent part of the scientific process, and that ignoring prior information (if explicitly available from prior research) would be blatantly unscientific, the main point to make here is that this choice *is not an arbitrary one*.  There are many distributions we might work with, but some will be better for us than others.  Again, we'll revisit this topic later. While we will only work with one prior, I provide others you can play with. <span class="marginnote">Choose the prior that makes most sense to you.  If I were thinking logically, I might choose a prior that reflects that all advantage is to a person that spends their entire life kicking a ball, and if they can simply kick to the upper right or left of the goal, even with only moderate pace, they could point it out like Babe Ruth and simple physics (i.e. that the goalie can never reach the ball) would mean they score 95% of the time under perfect conditions. We might revise it downward to account for unspecified things, e.g. how tired they are, weather etc. A prior based on a beta distribution $\texttt{beta(9,1)}$, with a mean of .90, would perhaps be about right.  Of course the *data* would eventually suggest something much lower.</span>

```{r binomGoalPrior}
### prior distribution
# triangular as in Kruschke text example
pTheta = pmin(theta, 1-theta)

# uniform
# pTheta = dunif(theta)

# beta prior with mean = .5
# pTheta = dbeta(theta, 10, 10)

# Normalize so that values sum to 1
pTheta = pTheta/sum(pTheta) 
```

So given some estimate of $\theta$, we have a probability of that value based on our chosen prior.


## Likelihood

Next we will compute the <span class="emph">likelihood</span> of the data given some value of $\theta$.  Generally, the likelihood for some target variable $y$, with observed values $i \dots n$, given some (set of) parameter(s) $\theta$, can be expressed as follows:



$$p(y|\theta) = \prod_{i}^{n} p(y_i|\theta)$$


Specifically, the likelihood function for the binomial can be expressed as:


$$p(y|\theta) = {N \choose k}\, \theta^k\,  (1-\theta)^{N-k}$$


where $N$ is the total number of possible times in which the event  of interest could occur, and $k$ number of times the event of interest occurs. Our maximum likelihood estimate in this simple setting would simply be the proportion of events witnessed out of the total number of samples[^binomll]. We'll use the formula presented above.  Technically, the first term is not required, but it serves to normalize the likelihood as we did with the prior.  

```{r binomGoallikelihood, echo=2}
# use the formula
pDataGivenTheta = choose(N, nGoal) * theta^nGoal * (1-theta)^nMiss


# Alternative methods
# # get the liklihood for each value given each theta
# pDataGivenTheta2 = dbinom(6, size=10, prob=theta)
# pDataGivenTheta3 = sapply(theta, function(p) dbinom(driveNum, size=1, prob=p))
# # 
# # # columns represent a given theta estimate, rows the likelihood for each observation
# # head(pDataGivenTheta0, 3)
# # 
# # # get the products of the columns
# pDataGivenTheta3 = apply(pDataGivenTheta3, 2, prod) 
# pDataGivenTheta3 = pDataGivenTheta/sum(pDataGivenTheta) #normalize as with the prior
```

<span class="marginnote">Note that if we had covariates as in a regression model, we would have different estimates of theta for each observation, and thus would calculate each observation's likelihood and then take their product or sum their log values, see the [Maximum Likelihhood Review][Maximum Likelihood Review] for further details). Even here, if you turn this into binary logistic regression with 10 outcomes of goal scored vs. not, the 'intercept only' model would be identical to our results here.</span>

## Posterior

Given the prior and likelihood, we can now compute the <span class="emph">posterior distribution</span> via Bayes theorem. The only thing left to calculate is the denominator from Bayes theorem, then plug in the rest.

```{r binomGoalPosterior}
pData = sum(pDataGivenTheta*pTheta)  # marginal probability of the data

pThetaGivenData = pDataGivenTheta*pTheta / pData  # Bayes theorem
```

Now lets examine what all we've got.

```{r binomGoalResult, echo=F}
out = data.frame(theta, prior=pTheta, likelihood=pDataGivenTheta, posterior=pThetaGivenData)
# htmlTable::htmlTable(format(round(out, 3), nsmall = 3), rnames=F)
DT::datatable(format(round(out, 3), nsmall = 3), width='50%',
              rownames=F,
              options=list(ordering=F, paging=F, searching=F, info=F, autowidth=F,
                           columnDefs = list(list(className = 'dt-center', targets = 0:3))))

# pander::pander(format(round(out, 3), nsmall = 3), width='250px')
```

Starting with the *prior* column, we can see that with the triangular distribution, we've given most of our prior probability to the middle values with probability tapering off somewhat slowly towards either extreme.  The likelihood suggests the data is most likely for $\theta$ values .55-.64, though we know the specific maximum likelihood estimate for $\theta$ is the proportion for the sample, or .6.  Our posterior will fall somewhere between the prior and likelihood estimates, and we can see it has shifted the bulk of the probability slightly away from most likely values suggested by the prior distribution towards a $\theta$ value suggested by the data of .6.

Let's go ahead and see what the mean is: <span class="marginnote">The expected value for a continuous parameter is $\operatorname{E}[X] = \int_{-\infty}^\infty xp(x)\mathrm{d}x$, and for a discrete parameter $\operatorname{E}[X] = \sum_{i=1}^\infty x_i\, p_i$, i.e. a weighted sum of the possible values times their respective probability of occurrence.</span>


```{r binomPosteriorMean}
posteriorMean = sum(pThetaGivenData*theta)
posteriorMean
```

So we start with a prior centered on a value of $\theta=.5$, add data whose ML estimate is $\theta=.6$, and our posterior distribution suggests we end up somewhere in between.

We can perhaps understand this further via the following visualizations. In each of these the prior is represented by the blue density, the likelihood by the red, and the posterior by purple.  This first is based on a different prior than just used in our example, and instead employs the beta distribution noted among the possibilities in the [code above][Prior].  While the beta distribution is highly flexible, with shape parameters $\mathcal{A}$ and $\mathcal{B}$ set to 10 and 10 we get a symmetric distribution centered on $\theta = .5$.  This would actually be a somewhat stronger prior than we might normally want to use, but serves to illustrate a point.  The mean of the beta is $\frac{\mathcal{A}}{\mathcal{A}+\mathcal{B}}$, and thus has a nice interpretation as a prior based on data with sample size equal to $\mathcal{A}+\mathcal{B}$.  The posterior distribution that results would have a mean somewhere between the maximum likelihood value and that of the prior. With the stronger prior, the posterior is pulled closer to it.


```{r prior2post_1, echo=F, eval=T}
set.seed(1234)
nGoal = 6       # number of scores
nMiss = 4           # number not
theta = seq(from=.00001, to = .9999, length=5000)
pTheta = dbeta(theta, 10, 10)
pTheta = pTheta/sum(pTheta) # Normalize so sum to 1
pDataGivenTheta =  theta^nGoal * (1-theta)^nMiss
pDataGivenTheta = pDataGivenTheta/sum(pDataGivenTheta)
pData = sum(pDataGivenTheta*pTheta)
pThetaGivenData = pDataGivenTheta*pTheta  / pData

probdat = data.frame(prior=pTheta, likelihood=pDataGivenTheta, posterior=pThetaGivenData)

# use ggplot or plotly depending on what works
library(ggplot2)
g = ggplot(aes(x=theta), data=probdat, xlim=c(0,1)) +
  geom_polygon(aes(y=prior), fill='blue', alpha=.25) +
  # annotate('text',x=.2, y=3e-4, label='Prior&nbsp;with&nbsp;beta(10, 10)', color=alpha('blue', .75), parse=T) + # doesn't work with ggplot (use~); but does with plotly
  annotate('text',x=.2, y=3e-4, label='Prior~with~beta(10, 10)', color=alpha('blue', .75), parse=T) + # doesn't work with ggplot (use~); but does with plotly
  geom_polygon(aes(y=likelihood), fill='red', alpha=.25) +
  annotate('text', x=.8, y=4e-4, label='Likelihood', color='darkred') +
  geom_polygon(aes(y=posterior), fill='purple', alpha=.25) +
  annotate('text', x=.4, y=8e-4, label='Posterior', color='purple') +
  ylab('Density') +
  xlab(substitute('theta')) +
  lazerhawk::theme_trueMinimal() +
  theme(axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_text(color='gray35'),
        axis.title.x=element_text(color='gray35'),
        plot.background = element_rect(fill = "transparent",colour = NA),
        panel.background=element_rect(fill = "transparent",colour = NA))
g

# PLOTLY CURRENTLY BREAKS MATHJAX, FANTASTIC!
# library(plotly)
# ggplotly(tooltip='none') %>%
#   config(displayModeBar=F) %>%
#   layout(paper_bgcolor=rgb(0,0,0,0), plot_bgcolor=rgb(0,0,0,0))
```


The second utilizes a more diffuse prior of $\beta(2,2)$. <span class="marginnote">$\beta(1,1)$ is a uniform distribution.</span>  The result of using the vague prior is that the likelihood gets more weight with regard to the posterior.  In fact, if we used a uniform distribution, *we would essentially be doing the equivalent of maximum likelihood estimation*.  In that sense, many of the commonly used methods that implement maximum likelihood can be seen as a special case of a Bayesian approach.

```{r prior2post_2, echo=FALSE}
### more vague prior
set.seed(1234)
nGoal = 6       # number of scores
nMiss = 4           # number not
pTheta = dbeta(theta, 2, 2)
pTheta = pTheta/sum(pTheta) # Normalize so sum to 1
pDataGivenTheta = theta^nGoal * (1-theta)^nMiss
pDataGivenTheta = pDataGivenTheta/sum(pDataGivenTheta)
pData = sum(pDataGivenTheta*pTheta)
pThetaGivenData = pDataGivenTheta*pTheta  / pData

probdat = data.frame(prior=pTheta, likelihood=pDataGivenTheta, posterior=pThetaGivenData)


g = ggplot(aes(x=theta), data=probdat, xlim=c(0,1)) +
  geom_polygon(aes(y=prior), fill='blue', alpha=.25) +
  # annotate('text',x=.25, y=3e-4, label='Prior&nbsp;with&nbsp;beta(2, 2)', color='blue', parse=T) +
  annotate('text',x=.25, y=3e-4, label='Prior~with~beta(2, 2)', color='blue', parse=T) +
  geom_polygon(aes(y=likelihood), fill='red', alpha=.25) +
  annotate('text', x=.8, y=5e-4, label='Likelihood', color='darkred') +
  geom_polygon(aes(y=posterior), fill='purple', alpha=.25) +
  annotate('text', x=.4, y=5e-4, label='Posterior', color='purple') +
  ylab('Density') +
  xlab(expression('theta')) +
  lazerhawk::theme_trueMinimal() +
  theme(axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_text(color='gray35'),
        axis.title.x=element_text(color='gray35'),
        plot.background = element_rect(fill = "transparent",colour = NA),
        panel.background=element_rect(fill = "transparent",colour = NA))
g
# ggplotly()
```


The third graph employs the initial $\beta(10,10)$ prior again, but this time we add more observations to the data.  Again this serves to give more weight to the likelihood, which is what we want.  As scientists, we'd want the evidence, i.e. data, to eventually outweigh our prior beliefs about the state of things the more we have of it. 


```{r  prior2post_3, echo=FALSE}
### more data
set.seed(1234)
N = 50
drive = rbinom(N, size=1, p=.6)
nGoal = sum(drive==1)       # number of scores
nMiss = sum(drive==0)           # number not


pTheta = dbeta(theta, 10, 10)
pTheta = pTheta/sum(pTheta) # Normalize so sum to 1
pDataGivenTheta = theta^nGoal * (1-theta)^nMiss
pDataGivenTheta = pDataGivenTheta/sum(pDataGivenTheta)
pData = sum(pDataGivenTheta*pTheta)
pThetaGivenData = pDataGivenTheta*pTheta  / pData

probdat = data.frame(prior=pTheta, likelihood=pDataGivenTheta, posterior=pThetaGivenData)


g = ggplot(aes(x=theta), data=probdat, xlim=c(0,1)) +
  geom_polygon(aes(y=prior), fill='blue', alpha=.25) +
  # annotate('text',x=.25, y=6e-4, label='Prior&nbsp;with&nbsp;beta(10, 10)', color='blue', parse=T) +
  annotate('text',x=.25, y=6e-4, label='Prior~with~beta(10, 10)', color='blue', parse=T) +
  geom_polygon(aes(y=likelihood), fill='red', alpha=.25) +
  annotate('text', x=.8, y=1e-3, label=paste('Likelihood with N =', N), color='darkred') +
  geom_polygon(aes(y=posterior), fill='purple', alpha=.25) +
  annotate('text', x=.45, y=1e-3, label='Posterior', color='purple') +
  ylab('Density') +
  xlab('theta') +
  lazerhawk::theme_trueMinimal() +
  theme(axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_text(color='gray35'),
        axis.title.x=element_text(color='gray35'),
        plot.background = element_rect(fill = "transparent",colour = NA),
        panel.background=element_rect(fill = "transparent",colour = NA))
g


# ggplotly()
```

For an interactive demonstration of the above, [see this](https://micl.shinyapps.io/prior2post/).


## Posterior predictive

At this point it is hoped you have a better understanding of the process of Bayesian estimation.  Conceptually, one starts with prior beliefs about the state of the world and adds evidence to one's understanding, ultimately coming to a conclusion that serves as a combination of evidence and prior belief.  More concretely, we have a prior distribution regarding parameters, a distribution regarding the data given those parameters, and finally a posterior distribution that is the weighted combination of the two.

However there is yet another distribution of interest to us- the <span class="emph">posterior predictive distribution</span>.  Stated simply, once we have the posterior distribution for $\theta$, we can then feed (possibly new or unobserved) data into the data generating process and get distributions for $\tilde{y}$[^postpred]. Where $\tilde{y}$ can regard *any* potential observation, we can distinguish it from the case where we use the current data to produce $y^{\textrm{Rep}}$, i.e. a replicate of $y$. For example, if a regression model had predictor variables $X$, the predictor variables are identical for producing $y^{\textrm{Rep}}$ as they were in modeling $y$.  However, $\tilde{y}$ might be based on any values $\tilde{X}$ that might be feasible or interesting, whether actually observed in the data or not.  Since $y^{\textrm{Rep}}$ is an attempt to replicate the observed data based on the parameters $\theta$, we can compare our simulated data to the observed data to see how well they match. 

We can implement the simulation process with the data and model at hand, given a sample of values of $\theta$ drawn from the posterior. I provide the results of such a process with the following graph. Each bar graph of frequencies represents a replication of the 10 shots taken, i.e. $y^{\textrm{Rep}}$, given an estimate of $\theta$ from the posterior distribution (16 total).  These are plausible sets of 10 makes and misses, given $\theta$.

<img src="img/histofyrepBinom.svg" style="display:block; margin: 0 auto; width=20%"></span>

```{r binomPostPred, cache=TRUE, message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}
# using bernoulli for 1 trial at a time; see Gelman p.32 
# NO LONGER NECESSARY, use rstan_arm
# datalist = list(y=shotsNum, N=length(shotsNum))
# modelcode <- "
# data{
#   int N;
#   int y[N];
# }
# 
# parameters{
#   real<lower=0, upper=1> theta;
# }
# 
# model{
#   theta ~ beta(5,5);
#   y ~ bernoulli(theta);
# }
# 
# generated quantities{
#   vector[N] yRep;
#   for (i in 1:N){
#     yRep[i] <- bernoulli_rng(theta);
#   }
# }
# "
# library(rstan)
# shotres = stan(model_code=modelcode, data=datalist, iter=12000, warmup=2000, thin=10, chains=2)
# shotres
# traceplot(shotres, 'theta')
# yrep = extract(shotres, 'yRep')$yRep
# dim(yrep)

shotres = stan_glm(shotsNum~1, family='binomial', iter=2250, warmup=1000, thin=10, prior=student_t())
yrep = data.frame(posterior_predict(shotres)); colnames(yrep) = paste0('Player_', 1:10)

sampleIndex = sample(1:500, 16)
yrepLong = tidyr::gather(data.frame(Sim=1:500, yrep)[sampleIndex, ], key=Player, value=Goal, -Sim) %>% 
  arrange(Sim)

library(ggplot2)
ggplot(aes(x=factor(Goal, labels=c('Misses', 'Makes'))), data=yrepLong) +
  geom_bar(fill='#ff5503', color=NA, alpha=.5, width=.5) +
  facet_wrap(~Sim, ncol=4) +
  labs(x='', y='') +
  theme_minimal() + 
  theme(panel.grid = element_blank(),
    # axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    # axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    strip.text = element_blank(),
    plot.background = element_rect(fill = "transparent",colour = NA))
ggsave('img/histofyrepBinom.svg', bg='transparent')
```


<br>

With an understanding of the key elements of Bayesian inference in hand, we can proceed to the still familiar but more complex and interesting setting of a regression model.

<!-- 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Prior likeilihood posterior triplots for posterity
 -->
```{r binomDriveDistplot, eval=FALSE, echo=FALSE}
set.seed(1234)
nGoal = 6       # number of scores
nMiss = 4           # number not
theta = seq(from=.00001, to = .9999, length=5000)
# pTheta = pmin(theta, 1-theta)
# pTheta = dunif(theta)
pTheta = dbeta(theta, 10, 10)
pTheta = pTheta/sum(pTheta) # Normalize so sum to 1
pDataGivenTheta =  theta^nGoal * (1-theta)^nMiss
pDataGivenTheta = pDataGivenTheta/sum(pDataGivenTheta)
pData = sum(pDataGivenTheta*pTheta)
pThetaGivenData = pDataGivenTheta*pTheta  / pData

probdat = data.frame(prior=pTheta, likelihood=pDataGivenTheta, posterior=pThetaGivenData)

library(ggplot2)
ggplot(aes(x=theta), data=probdat, xlim=c(0,1)) +
  geom_polygon(aes(y=prior), fill='blue', alpha=.25) +
  annotate('text',x=.2, y=3e-4, label='Prior&nbsp;with&nbsp;beta(10, 10)', color='blue', parse=T) + # doesn't work with ggplot (use~); but does with plotly
  geom_polygon(aes(y=likelihood), fill='red', alpha=.25) +
  geom_text(x=.8, y=4e-4, label='Likelihood', color='darkred') +
  geom_polygon(aes(y=posterior), fill='purple', alpha=.25) +
  geom_text(x=.4, y=8e-4, label='Posterior', color='purple') +
  ylab('Density') +
#   annotate('title', label='Prior~with~beta(10, 10)', parse=T) +
#   labs(title = expression("Prior~with~ beta(10, 10)"))
  lazerhawk::theme_trueMinimal() +
  theme(axis.ticks.y=element_line(color='white'),
        axis.text.y=element_text(color='white'),
        plot.background = element_rect(fill = "transparent",colour = NA))
# ggsave('figure/priorlikepost1.svg', width=3, height=3)
ggsave('figure/priorlikepost1.png', width=8, height=8, bg = "transparent") # png for faster loading

### more vague prior
set.seed(1234)
nGoal = 6       # number of scores
nMiss = 4           # number not
pTheta = dbeta(theta, 2, 2)
pTheta = pTheta/sum(pTheta) # Normalize so sum to 1
pDataGivenTheta = theta^nGoal * (1-theta)^nMiss
pDataGivenTheta = pDataGivenTheta/sum(pDataGivenTheta)
pData = sum(pDataGivenTheta*pTheta)
pThetaGivenData = pDataGivenTheta*pTheta  / pData

probdat = data.frame(prior=pTheta, likelihood=pDataGivenTheta, posterior=pThetaGivenData)


ggplot(aes(x=theta), data=probdat, xlim=c(0,1)) +
  geom_polygon(aes(y=prior), fill='blue', alpha=.25) +
  annotate('text',x=.3, y=3e-4, label='Prior~with~beta(2, 2)', color='blue', parse=T) +
  geom_polygon(aes(y=likelihood), fill='red', alpha=.25) +
  geom_text(x=.8, y=5e-4, label='Likelihood', color='darkred') +
  geom_polygon(aes(y=posterior), fill='purple', alpha=.25) +
  geom_text(x=.4, y=5e-4, label='Posterior', color='purple') +
  ylab('Density') +
#   annotate('title', label='Prior~with~beta(10, 10)', parse=T) +
#   labs(title = 'A more vague prior') +
  lazerhawk::theme_trueMinimal() +
  theme(axis.ticks.y=element_line(color='white'),
        axis.text.y=element_text(color='white'),
        plot.background = element_rect(fill = "transparent",colour = NA))
# ggsave('figure/priorlikepost2.svg', width=3, height=3)
ggsave('figure/priorlikepost2.png', width=8, height=8, bg = "transparent") # png for faster loading

### more data
set.seed(1234)
N = 50
drive = rbinom(N, size=1, p=.6)
nGoal = sum(drive==1)       # number of scores
nMiss = sum(drive==0)           # number not


pTheta = dbeta(theta, 10, 10)
pTheta = pTheta/sum(pTheta) # Normalize so sum to 1
pDataGivenTheta = theta^nGoal * (1-theta)^nMiss
pDataGivenTheta = pDataGivenTheta/sum(pDataGivenTheta)
pData = sum(pDataGivenTheta*pTheta)
pThetaGivenData = pDataGivenTheta*pTheta  / pData

probdat = data.frame(prior=pTheta, likelihood=pDataGivenTheta, posterior=pThetaGivenData)


ggplot(aes(x=theta), data=probdat, xlim=c(0,1)) +
  geom_polygon(aes(y=prior), fill='blue', alpha=.25) +
  annotate('text',x=.3, y=6e-4, label='Prior~with~beta(10, 10)', color='blue', parse=T) +
  geom_polygon(aes(y=likelihood), fill='red', alpha=.25) +
  geom_text(x=.8, y=1e-3, label=paste('Likelihood with N =', N), color='darkred') +
  geom_polygon(aes(y=posterior), fill='purple', alpha=.25) +
  geom_text(x=.45, y=1e-3, label='Posterior', color='purple') +
  ylab('Density') +
#   annotate('title', label='Prior~with~beta(10, 10)', parse=T) +
#   labs(title = expression("Prior~with~ beta(10, 10)"))
  lazerhawk::theme_trueMinimal() +
  theme(axis.ticks.y=element_line(color='white'),
        axis.text.y=element_text(color='white'),
        plot.background = element_rect(fill = "transparent",colour = NA))
# ggsave('figure/priorlikepost3.svg', width=3, height=3)
ggsave('figure/priorlikepost3.png', width=8, height=8, bg = "transparent") # png for faster loading

```


[^football]: Don't even start, it's always been both 'football' and 'soccer'.

[^binomll]: See for yourself in the [binmoial likelihood][Binomial Likelihood Example] section in the appendix.



[^postpred]: Mathematically represented as: $p(\tilde{y}|y) = \int p(\tilde{y}|\theta)p(\theta|y)\mathrm{d}\theta$ <br><br> We can get a sense of the structure of this process via the following table, taken from Gelman: <br><br> <img src="img/gelmanTable.png" style="display:block; margin: 0 auto;">


<!--chapter:end:02_example.Rmd-->


# Regression Models

Now armed with a conceptual understanding of the Bayesian approach, we will actually investigate a regression model using it.  To keep things simple, we start with a standard linear model for regression.  Later, we will show how easy it can be to add changes to the sampling distribution or priors for alternative modeling techniques. But before getting too far, you should peruse the [Modeling Languages][Modeling Languages] section of the appendix to get a sense of some of the programming approaches available.  We will be using the programming language Stan via R and the associated R package <span class="pack">rstan</span>.  If you prefer to keep things conceptual rather than worry about the code, you can read through the following data description and then skip to [running the model][Running the Model].<span class="marginnote">For just a standard regression model I would ultimately suggest using <span class="pack">rstanarm</span> or <span class="pack">brms</span>, because they would allow you to keep to the usual R approach for modeling, allowing you to more or less jump right in. However, writing Stan code makes it more clear what is being done, so we'll keep to it for our purposes here. When I first started writing this document, <span class="pack">brms</span> didn't exist, <span class="pack">rstanarm</span> was still in its infancy, there was no interactive <span class="pack">shinystan</span> etc. I may end up moving the Stan code to the appendix and just using <span class="pack">rstanarm</span> in the future, but I think it's worth knowing what's actually going on specifically behind the scenes, so will stick to the <span class="pack">rstan</span> approach for now.</span>


## Example: Linear Regression Model

In the following we will have some initial data set up and also run the model using the standard <span class="func">lm</span> function for later comparison.  I choose simulated data so that not only should you know what to expect from the model, it can easily be modified to enable further understanding.  I will also use some matrix operations, and if these techniques are unfamiliar to you, you'll perhaps want to do some refreshing or learning on your own beforehand.


## Setup

First we need to create the data we'll use here and for most of the other examples in this document.

```{r rstanDataSetup, echo=-c(1:4)}
##########################
### Initial Data Setup ###
##########################

# set seed for replicability
set.seed(8675309)

# create a N x k matrix of covariates
N = 250
K = 3

covariates = replicate(K, rnorm(n=N))
colnames(covariates) = c('X1', 'X2', 'X3')

# create the model matrix with intercept
X = cbind(Intercept=1, covariates)

# create a normally distributed variable that is a function of the covariates
coefs = c(5, .2, -1.5, .9)
mu = X %*% coefs
sigma = 2
y <- rnorm(N, mu, sigma)

# same as
# y = 5 + .2*X1 - 1.5*X2 + .9*X3 + rnorm(N, mean=0, sd=2)

# Run lm for later comparison; but go ahead and examine now if desired
modlm = lm(y~., data=data.frame(X[,-1]))
# summary(modlm)
```

Just to make sure we're on the same page, at this point we have three covariates, and a $y$ that is a normally distributed, linear function of them with standard deviation equal to `r sigma`.  The population values for the coefficients including the intercept are `r paste0(coefs[1:3], ', ', collapse='')` and `r coefs[4]`, though with the noise added, the actual estimated values for the sample are slightly different.  Now we are ready to set up an R list object of the data for input into Stan, as well as the corresponding Stan code to model this data.  I will show all the Stan code, which is implemented in R via a single character string, and then provide some detail on each corresponding model block.  However, the goal here isn't to focus on tools as it is to focus on concepts.
<span class="margin_note">Related code for this same model in BUGS and JAGS is provided in the appendix [here][Bugs Example]. I don't think there is an easy way to learn these programming languages except by diving in and using them yourself with models and data you understand.</span>

The data list for Stan should include any matrix, vector, or value that might be used in the Stan code.  For example, along with the data one can include things like sample size, group indicators (e.g. for mixed models) and so forth.  Here we can get by with just the N, the number of columns in the model matrix, the target variable and the model matrix itself.

```{r rstanDataList}
# Create the data list object for Stan input
dat = list(N=N, K=ncol(X), y=y, X=X)
```

Next comes the Stan code.  In <span class="pack">R2OpenBugs</span> or <span class="pack">rjags</span> one would call a separate text file with the code, and one can do the same with <span class="pack">rstan</span>[^stringvsfile], but for our purposes, we'll display it within the R code. The first thing to note then is the model code.  Next, Stan has programming blocks that have to be called in order. I will have all of the blocks in the code to note their order and discuss each in turn, even though we won't use them all.  Anything following a // or #, or between /\* \*/, are comments pertaining to the code.  Assignments in Stan are `=`[^assignment], while distributions are specified with a $\sim$, e.g. `y ~ normal(0, 1)` means y is normally distributed with mean 0 and standard deviation of 1.

The primary goal here again is to get to the results and beyond, but one should examine the [Stan manual](http://mc-stan.org/documentation/) for details about the code.  In addition, to install <span class="pack">rstan</span> one will need to do so via CRAN or Github ([quickstart guide](https://github.com/Stan-dev/rstan/wiki/RStan-Getting-Started)).  It does not require a separate installation of Stan itself, but it does take a couple steps and does require a C++ compiler[^compiler]. Once you have <span class="pack">rstan</span> installed it is called like any other R package as will see shortly.


```{r rstanStanSetup}
# Create the stan model object using Stan's syntax
stanmodelcode = "
data {                      // Data block
  int<lower=1> N;           // Sample size
  int<lower=1> K;           // Dimension of model matrix
  matrix[N, K] X;           // Model Matrix
  vector[N] y;              // Target variable
}

/* 
transformed data {          // Transformed data block. Not used presently.
} 
*/

parameters {                // Parameters block
  vector[K] beta;           // Coefficient vector
  real<lower=0> sigma;      // Error scale
}

model {                     // Model block
  vector[N] mu;
  mu <- X * beta;           // Creation of linear predictor
  
  // priors
  beta ~ normal(0, 10);
  sigma ~ cauchy(0, 5);     // With sigma bounded at 0, this is half-cauchy
  
  // likelihood
  y ~ normal(mu, sigma);
}

/*
generated quantities {      // Generated quantities block. Not used presently.
}
*/
"
```


### Stan Code

The first section is the <span class="emph">data</span> block, where we tell Stan the data it should be expecting from the data list.  It is useful to put in bounds as a check on the data input, and that is what is being done between the `< >` (e.g. we should at least have a sample size of 1).  The first two variables declared are `N` and `K`, both as integers.  Next the code declares the model matrix and target vector respectively. As you'll note here and for the next blocks, we declare the type and dimensions of the variable and then its name. In Stan, everything declared in one block is available to subsequent blocks, but those declared in a block may not be used in earlier blocks. Even within a block, anything declared, such as `N` and `K`, can then be used subsequently, as we did to specify dimensions of the model matrix `X`.

For a reference, the following is from the Stan manual, and notes variables of interest and the associated blocks where they would be declared.

```{r stanBlocks, results='asis', echo=FALSE}
tab = data.frame(c('modeled, unmodeled data', 'modeled parameters, missing data', 'unmodeled parameters', 'generated quantities', 'loop indices'),
                 c('data, transformed data', 'parameters, transformed parameters', 'data, transformed data', 'transformed data, transformed parameters, generated quantities','loop statement'))
colnames(tab) = c('Variable Kind', 'Declaration Block')
htmlTable::htmlTable(tab, rnames=F)
```

The <span class="emph">transformed data</span> block is where you could do such things as log or center variables and similar, i.e. you can create new data based on the input data or just in general.  If you are using R though, it would almost always be easier to do those things in R first and just include them in the data list.  You can also declare any unmodeled parameters here, e.g. those you want fixed at some value.

The primary parameters of interest that are to be estimated go in the <span class="emph">parameters </span> block.  As with the data block you can only declare these variables, you cannot make any assignments.  Here we note the $\beta$ and $\sigma$ to be estimated, with a lower bound of zero on the latter. In practice you might prefer to split out the intercept or other coefficients to be modeled separately if they are on notably different scales.

The <span class="emph">transformed parameters</span> block is where optional parameters of interest might be included.  What might go here is fairly open, but for efficiency's sake you will typically want to put things only of specific interest that are dependent on the parameters block.  These are evaluated along with the parameters, so if the objects are not of special interest you can instead generate them in the model or generated quantities block to save time.

The <span class="emph">model</span> block is where your priors and likelihood are specified, along with the declaration of any variables necessary.  As an example, the linear predictor is included here, as it will go towards the likelihood[^modelblock].  Note that we could have instead put the linear predictor in the transformed parameters section, but this would slow down the process, and again, we're not so interested in those specific values. 

I use a normal prior for the coefficients with a zero mean and a very large standard deviation to reflect my notable ignorance here[^regularize].  For the $\sigma$ estimate I use a Cauchy distribution[^cauchy].  Many regression examples using BUGS will use an inverse gamma prior, which is perfectly okay for this model, though it would not work so well for other variance parameters.  Had we not specified anything for the prior distribution for the parameters, vague (discussed more in the [Choice of Prior section][Choice of Prior]), uniform distributions would be the default. The likelihood is specified in a similar manner as one would with R. BUGS style languages would actually use <span class="func">dnorm</span> as in R, though Stan uses <span class="func">normal</span> for the function name.

Finally, we get to the <span class="emph">generated quantities</span>, which is kind of a fun zone. *Anything* you want to calculate can go here - predictions on new data, ratios of parameters, how many times a parameter is greater than x, transformations of parameters for reporting purposes, and so forth.  We will demonstrate this later.


### Running the Model

Now that we have an idea of what the code is doing, let's put it to work.  Bayesian estimation, like maximum likelihood, starts with initial guesses as starting points and then runs in an iterative fashion, producing simulated draws from the posterior distribution at each step, and then correcting those draws until finally getting to some target, or <span class="emph">stationary</span> distribution. This part is key and different from classical statistics.  We are aiming for a *distribution*, not a *point estimate*.

The simulation process is referred to as <span class="emph">Markov Chain Monte Carlo</span>, or MCMC for short.  The specifics of this process are what sets many of the Bayesian programming languages/approaches apart, and something we will cover in more detail in a later section (see [Sampling Procedure][Sampling Procedure]).  In MCMC, all of the simulated draws from the posterior are based on and correlated with previous draws[^mcmccor], as the process moves along the path toward a stationary distribution.  Typically we will allow the process to *warm up*, or rather get a bit settled down from the initial starting point, which might be way off, and thus the subsequent estimates will also be way off for the first few iterations. <span class="marginnote">How far one wants to go down the rabbit hole regarding MCMC is up to the reader.  A great many applied researchers do classical statistical analysis without putting much thought into the actual maximum likelihood estimation process, and I suppose one could do so here as well.</span> Rest assured, assuming the model and data are otherwise acceptable, the process will get to where it needs to go.  However, as a further check, we will run the whole thing multiple times, i.e. have more than one <span class="emph">chain</span>.  As the chains will start from different places, if multiple chains get to the same place in the end, we can feel more confident about our results.


While this process may sound like it might take a long time to complete, for the following you'll note that it will likely take more time for Stan to compile its code to C++ than it will to run the model[^speed], and on my computer each chain only takes only a little more than a second.  However, the Bayesian approach used to take a very long time even for a standard regression such as this, and that is perhaps the primary reason why Bayesian analysis only caught on in the last couple decades; we simply didn't have the machines to do it efficiently.  Even now though, for highly complex models and large data sets it can still take a long time to run, though typically not prohibitively so.

In the following code, we note the object that contains the Stan model code, the data list, how many iterations we want (12000)[^toomanyiter], how long we want the process to run before we start to keep any estimates (`warmup=2000`), how many of the post-warmup draws of the posterior we want to keep (`thin=10` means every tenth draw), and the number of chains (`chains=3`).  In the end we will have three chains of 1000<span class="marginnote">$\frac{12000-2000}{10} = 1000$</span> draws from the posterior distribution of the parameters.  Stan spits out a lot of output to the R console even with `verbose = FALSE`, and I omit it here, but you will see some initial info about the compiling process, updates as each chain gets through 10% of iterations specified in the `iter` argument, and finally an estimate of the elapsed time.  You may also see *informational messages* which, unless they are highly repetitive, should not be taken as an error.


```{r rstanRunModel, eval=F}
library(rstan)

### Run the model and examine results ###
fit = stan(model_code=stanmodelcode, data=dat, iter=12000, 
           warmup=2000, thin=10, chains=3)
```

```{r, echo=F, eval=F}
save(fit, modlm, X, y, file='miscObjects/mainModels.RData')# for use in standalone chaps
```


With the model run, we can now examine the results.  In the following, we specify the digit precision to display, which parameters we want (not necessary here), and which quantiles of the posterior draws we want, which in this case are the median and those that would produce a 95% interval estimate. 

```{r rstanModelSummary, echo=-1}
load('data/mainModels.RData')
# summary
print(fit, pars=c('beta', 'sigma'), digits=3, prob=c(.025,.5,.975))
```

So far so good.  The mean estimates reflect the mean of posterior draws for the parameters of interest, and are the typical coefficients reported in standard regression analysis.  The 95% probability, or, <span class="emph">credible intervals</span> are worth noting, because *they are not confidence intervals as you know them*.  There is no repeated sampling interpretation here[^confint].  The probability interval is more intuitive. It means simply that, based on the results of this model, there is a 95% chance the true value will fall between those two points.  The other values printed out I will return to in just a moment.

Comparing the results to those from R's <span class="func">lm</span> function, we can see we obtain similar estimates, as they are identical to two decimal places. In fact, had we used uniform priors[^justlikelm], we would doing essentially the same model as what is being conducted with standard maximum likelihood estimation.  Here, we have a decent amount of data for a model that isn't complex, so we would expect the likelihood to notably outweigh the prior, as we demonstrated previously with our binomial example.

```{r rstanCompareStanlm}
summary(modlm)
```

But how would we know if our model was working out okay otherwise?  There are several standard diagnostics, and we will talk about them in more detail in the next section, but let's take a look at some presently.  In the summary, `se_mean` is the <span class="emph">Monte Carlo error</span>, and is an estimate of the uncertainty contributed by only having a finite number of posterior draws. `n_eff` is <span class="emph">effective sample size</span> given all chains, and essentially accounts for autocorrelation in the chain, i.e. the correlation of the estimates as we go from one draw to the next. It actually doesn't have to be very large, but if it was small relative to the total number of draws desired that might be cause for concern.  `Rhat` is a measure of how well chains mix, and goes to 1 as chains are allowed to run for an infinite number of draws.  In this case, `n_eff` and `Rhat` suggest we have good convergence, but we can also examine this visually with a traceplot.


```{r rstanModelDiagnostics, eval=F, fig.align='center'}
# Visualize
stan_trace(fit, pars=c('beta[4]'))
```

<span class="imgbigger"><img src="img/traceplotWarmup.svg" width=75% style="display:block; margin: 0 auto;"></span>

```{r rstanModelDiagnostics2, echo=F, eval=FALSE}
# library(rstan)
# stan_trace(fit, pars=c('beta[4]'), inc_warmup=F) + 
#   labs(y='x3 Coefficient Estimate', x='Iteration') + 
#   theme_minimal() + 
#   theme(panel.grid=element_blank(),
#         plot.background=element_rect(fill='transparent', color=NA))   # as of 5-2016, rstan's traceplot isn't working properly, and is ugly anyway
beta4 = extract(fit, pars=c('beta[4]'), inc_warmup=T, permute=F)[,,1]
beta4 = tidyr::gather(data.frame(beta4), key=chain, value=estimate) %>% mutate(Iteration=rep(1:1200, t=3))
ggplot(data=beta4) +
  annotate("rect", xmin = 0, xmax = 200, ymin = -Inf, ymax = Inf, fill = 'black', alpha=.1) +
  geom_path(aes(x=Iteration, y=estimate, color=chain), alpha=.5)  +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  scale_x_continuous(limits=c(0,1200), breaks=c(200,500,750,1000,1200)) +
  labs(x='Iteration', y='Estimate') +
  lazerhawk::theme_trueMinimal() +
  theme(plot.background=element_rect(fill='transparent', color=NA),
        legend.background=element_rect(fill='transparent', color=NA),
        legend.title=element_blank())
ggsave('img/traceplotWarmup.svg', bg='transparent')

# pdf('img/traceplotNoWarmup.pdf')
# traceplot(fit, pars=c('beta','sigma'), inc_warmup=F)
# dev.off()
# plot(fit, pars=c('beta','sigma')) # ugh
# pairs(fit, pars=c('beta','sigma'))
```

I only show one parameter for the current demonstration, but one should always look at the traceplots for all parameters.  What we are looking for after the warmup period is a "fat hairy caterpillar" or something that might be labeled as "grassy", and this plot  qualifies as such[^diagnostics]. One can see that the estimates from each chain find their way from the starting point to a more or less steady state quite rapidly (initial warmup iterations in gray).  Furthermore, all three chains, each noted by a different color, are mixing well and bouncing around the same conclusion. The statistical measures and traceplot suggest that we are doing okay.

The Stan development crew has made it easy to interactively explore diagnostics via the <span class="pack">shinystan</span> package, and one should do so with each model.  In addition, there are other diagnostics available in the <span class="pack">coda</span> package, and Stan model results can be easily converted to work with it.  The following code demonstrates how to get started.

```{r rstanToCoda, eval=FALSE, echo=1:4}
library(coda)
betas = extract(fit, pars='beta')$beta
betas.mcmc = as.mcmc(betas)
plot(betas.mcmc)

pdf('img/codaPlot.pdf')
betas.mcmc = as.mcmc(extract(fit, pars='beta', permuted=F)[,1,])
plot(betas.mcmc, col='gray50', bty='n', main='', xlab='')
dev.off()
apply(betas.mcmc, 2, function(x) ks.test(x, rnorm(1000, mean(x), sd(x))))
apply(betas.mcmc, 2, shapiro.test)
```

So there you have it.  Aside from the initial setup with making a data list and producing the language-specific model code, it doesn't necessarily take much to running a Bayesian regression model relative to standard models[^otherpacks].  The main thing perhaps is simply employing a different mindset, and interpreting the results from within that new perspective.  For the standard models you are familiar with, it probably won't take too long to be as comfortable here as you were with those, and now you will have a flexible tool to take you into new realms with deeper understanding.



[^assignment]: `<-` is now deprecated, but you may see older examples using it.

[^bugs2stan]: In general their modeling syntax is not too difficult to translate from Stan and often very similar.

[^stringvsfile]: In your own Stan pursuits it's better to have the Stan model as a separate file.

[^compiler]: You can examine this [list](https://en.wikipedia.org/wiki/List_of_compilers\#C.2B.2B_compilers) of compilers, or on Windows simply install Rtools from the R website (recommended). Note that you may already have one incidentally.  Try the Stan test in their 'getting started' guide before downloading one.

[^modelblock]: The position within the model block isn't crucial. I tend to like to do all the variable declarations at the start, but others might prefer to have them under the likelihood heading at the point they are actually used.

[^regularize]: By setting the prior mean to zero, this will have the effect of shrinking the coefficients toward zero to some extent.  In this sense, it is equivalent to penalized regression in the non-Bayesian setting, ridge regression in particular.

[^cauchy]: Actually a half-Cauchy as it is bounded to be positive. This is equivalent to a student t with df=1, and there is some tendency of late to use the student t directly with df=3 for slight gains in performance for some models.

[^mcmccor]: In a Markov Chain, $\theta_t$ is independent of previous $\theta_{t-2...t_1}$, conditional on $\theta_{t-1}$.

[^speed]: Not usually the case except for simple models with smaller data.

[^toomanyiter]: This is way overkill for a simple model like this.  One probably would be fine with 500 warmup and 500 iterations for a standard regression.

[^confint]: A standard confidence implies that if we'd done the study exactly the same over and over, and calculated a confidence interval each time, 95% of them would capture the true value. The one you have is just one from that process.

[^justlikelm]: In Stan code this can be done by not explicitly specifying a prior.

[^diagnostics]: Like all model diagnostics, we aren't dealing with an exact science.

[^otherpacks]: As noted previously, other R packages would allow for regression models to be specified just like you would with the <span class="func">lm</span> and <span class="func">glm</span> functions.  See the <span class="pack">rstanarm</span> (from the developers of Stan) and <span class="pack">brms</span> packages especially.

<!--chapter:end:03_models.Rmd-->

# Model Checking & Diagnostics

As<span class="marginnote">I wonder how many results have been published on models that didn't converge with the standard MLE.  People will often ignore warnings as long as they get a result.</span> with modeling in traditional  approaches, it is not enough to simply run a model and get some sort of result.  One must examine the results to assess model integrity and have more confidence in the results that have been produced.


## Monitoring Convergence

There are various ways to assess whether or not the model has converged to a target distribution[^targetdist], but as with more complex models in MLE, there is nothing that can tell you for sure that you've hit upon *the* solution.  As a starting point, Stan or other modeling environments will spit out repeated warnings or errors if something is egregiously wrong, or perhaps take an extraordinary time to complete relative to expectations, if it ever finishes at all.  Assuming you've at least gotten past that point, there is more to be done.

### Visual Inspection: Traceplot & Densities

In the previous model we noted the traceplot for a single parameter, and a visual approach to monitoring convergence is certainly one good method.  In general we look for a plot that shows random scatter around a mean value, and our model results suggest that the chains mixed well and the traceplot looked satisfactory.<span class="marginnote"><span class="imgbigger"><img src="img/badchains.svg" style="display:block; margin: 0 auto;"  width=75%></span></span>

To the right I provide an example where things have gone horribly wrong.  The chains never converge nor do they mix with one another.  However, one reason for running multiple chains is that any individual chain might converge toward one target, while another chain might converge elsewhere, and this would still be a problem.  Also you might see otherwise healthy chains get stuck on occasion over the course of the series, which might suggest more model tweaking or a change in the sampler settings is warranted.

We can examine the mixed chains and density plots of the posterior together with the <span class="pack">rstan</span> or <span class="pack">shinyStan</span> package plot function displayed in the model example or <span class="func">launch_shiny</span> in the <span class="pack">brms</span> package.<span class="marginnote"><span class="imgbigger"><img src="img/shinyStan.png" style="display:block; margin: 0 auto;"></span></span>  In the Bayesian approach, increasing amounts of data leads to a posterior distribution of the parameter vector approaching multivariate normality.  The figure to the right shows a density, trace and autocorrelation plots for one of the regression coefficients using shinyStan.  

```{r badChain, eval=FALSE, echo=FALSE}
# see https://groups.google.com/forum/#!topic/stan-users/hio0siMTvhE
# unidentified model
mc_bad2 <- '
data{
    int N;
    real y[N];
}
parameters{
    real a1;
    real a2;
    real<lower=0> sigma;
}
model{
    y ~ normal( a1+a2 , sigma );
}
'

library(rstan)
y <- rnorm(100)
m_bad3 <- stan(model_code=mc_bad2 , data=list(y=y,N=length(y)) )
traceplot(m_bad3, par='a1', yaxt='n')
library(coda)
traceplot(as.mcmc(extract(m_bad3, 'a1', permuted=F)$a1))
showMethods(traceplot, class = "stanfit", include = TRUE) 

library(ggplot2); library(reshape2)
gdat = melt(data.frame(extract(m_bad3, 'a1', permuted=F)[,,1]))
ggplot(aes(x=rep(1:1000, 4), y=value, color=variable, group=variable), data=gdat) +
  geom_line(show.legend=F) + 
  labs(x='', y='') +
  lazerhawk::theme_trueMinimal() + 
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        plot.background=element_rect(fill = "transparent",colour = NA))
# ggsave('img/badchains.pdf', width=11, height=8.5)
ggsave('img/badchains.svg', width=11, height=8.5, bg='transparent')
# ggsave('img/badchains.png', width=11, height=8.5, bg='transparent')
```

### Statistical Measures

To go along with visual inspection, we can examine various statistics that might help our determination of convergence or lack thereof.  Gelman and Rubin's <span class="emph">potential scale reduction factor</span>, $\hat{R}$, provides an estimate of convergence based on the variance of an estimate $\theta$ between chains and the variance within a chain. It is interpreted as the factor by which the variance in the estimate might be reduced with longer chains.  We are looking for a value near 1 (and at the very least less than 1.1), and it will get there as $N_{sim} \rightarrow \infty$.

The <span class="pack">coda</span> package provides other convergence statistics based on Geweke (1992) and Heidelberger and Welch (1983).  Along with those statistics, it also has plots for the $\hat{R}$ and Geweke diagnostics.


### Autocorrelation

As noted previously, each estimate in the MCMC process is serially correlated with the previous estimates by definition.  Furthermore, other aspects of the data, model, and estimation settings may contribute to this. <span class="marginnote"><span class="imgbigger"><img src="img/acfPlotNoSerial.svg" style="display:block; margin: 0 auto;" width=50%></span></span> <span class="marginnote"><span class="imgbigger"><img src="img/acfPlotSerial.svg" style="display:block; margin: 0 auto;" width=50%></span></span>  Higher serial correlation typically has the effect of requiring more samples in order to get to a stationary distribution we can feel comfortable with. If inspection of the traceplots look more *snake-like* than like a fat hairy caterpillar, this might suggest such a situation, and that more samples are required. We can also look at the autocorrelation plot, in which the chain's correlation with successive lags of the chain are plotted.  The first plot to the right is the autocorrelation plot from our model (starting at lag 1). The correlation is low to begin with and then just bounces around zero after.  The next plot shows a case of high serial correlation, where the correlation with the first lag is high and the correlation persists even after longer lags.  A longer chain with more thinning could help with this.

The effective number of simulation draws is provided as $n_{\textrm{eff}}$ in the Stan output and similarly obtained in BUGS/JAGS.  We would desire this number to equal the number of posterior draws requested.  In the presence of essentially no autocorrelation the values would be equal.  This is not a requirement though, and technically a low number of draws would still be usable.  However, a notable discrepancy might suggest there are some issues with the model, or simply that longer chains could be useful.

<span class="emph">Monte Carlo error</span> is an estimate of the uncertainty contributed by only having a finite number of posterior draws. Typically we'd want roughly less than 5% of the posterior standard deviation (reported right next to it in the Stan output), but might as well go for less than 1%. With no autocorrelation it would equal $\sqrt{\frac{var(\theta)}{n_{\textrm{eff}}}}$[^mcerr]. and $n_{\textrm{eff}}$ would equal the number of simulation draws requested.


```{r autocorrExample, eval=FALSE, echo=FALSE}
# first do original acf
library(coda)
betas = extract(fit, pars='beta', permuted=F)[,1:3,4] #1st chain beta4
betas.mcmc = as.mcmc(betas)
# pdf('img/acfPlotNoSerial.pdf')
# acfplot(betas.mcmc[,1])
# dev.off()
# acf(betas.mcmc[,1], bty='n', col='#ff5503', lwd=3, main='', ci.col=scales::alpha('blue',.5), 
#     xaxt='n', ylab='Autocorrelation', col.lab='gray25', col.axis='gray50')

test0 <- acf(betas.mcmc[,1], plot = FALSE)
test <- with(test0, data.frame(lag, acf))
ggplot(data = test, mapping = aes(x = lag, y = acf)) +
       geom_hline(aes(yintercept = 0), col='gray90') +
       geom_segment(mapping = aes(xend = lag, yend = 0), col='#ff5503', lwd=6) +
  labs(x='Lag',  y='Autocorrelation') +
  lazerhawk::theme_trueMinimal() +
  theme(axis.title.x=element_text(color='gray25'),
        axis.title.y=element_text(color='gray25'),
        plot.background = element_rect(fill = "transparent",colour = NA))
ggsave('img/acfPlotNoSerial.svg', bg='transparent')

pres2 = presidents; pres2[1] = 87
for(i in 2:length(pres2)){
  pres2[i] = ifelse(is.na(pres2[i]), pres2[i-1], pres2[i])
}
# pdf('img/acfPlotSerial.pdf')
# acfplot(as.mcmc(pres2))
# dev.off()
test0 <- acf(as.mcmc(pres2), plot = FALSE)
test <- with(test0, data.frame(lag, acf))
ggplot(data = test, mapping = aes(x = lag, y = acf)) +
       geom_hline(aes(yintercept = 0), col='gray90') +
       geom_segment(mapping = aes(xend = lag, yend = 0), col='#ff5503', lwd=6) +
  labs(x='Lag',  y='Autocorrelation') +
  lazerhawk::theme_trueMinimal() +
  theme(axis.title.x=element_text(color='gray25'),
        axis.title.y=element_text(color='gray25'),
        plot.background = element_rect(fill = "transparent",colour = NA))
ggsave('img/acfPlotSerial.svg', bg='transparent')
```


## Model Checking

Checking the model for suitability is crucial to the analytical process[^ppcheck].  Assuming initial diagnostic inspection for convergence has proven satisfactory, we must then see if the model makes sense in its own right.  This can be a straightforward process in many respects, and with  Bayesian analysis one has a much richer environment in which to do so compared to traditional methods.

### Sensitivity Analysis

Sensitivity analysis entails checks on our model settings to see if changes in them, perhaps even slight ones, result in changes in posterior inferences.  This may take the form of comparing models with plausible but different priors, different sampling distributions, or differences in other aspects of the model such as the inclusion or exclusion of explanatory variables.  While an exhaustive check is impossible, at least some effort in this area should be made.

### Predictive Accuracy & Model Comparison

A standard way to check for model adequacy is simply to investigate whether the predictions on new data are accurate.  In general, the measure of predictive accuracy will be specific to the data problem, and involve posterior simulation of the sort covered in the next section.  In addition, while oftentimes new data is hard to come by, assuming one has sufficient data to begin with, one could set aside part of it specifically for this purpose. In this manner one trains and tests the model in much the same fashion as machine learning approaches.  In fact, one can incorporate the validation process as an inherent part of the modeling process in the Bayesian context just as you would there.  

For model comparison of out of sample predictive performance, there are information measures similar to the Akaike Information criterion (AIC), that one could use in the Bayesian environment.  One not to use is the so-called Bayesian information criterion (or BIC), which is not actually Bayesian nor a measure of predictive accuracy.  BUGS provides the DIC, or deviance information criterion, as part of its summary output, which is a somewhat Bayesian version of the AIC.  More recently developed, the WAIC, or Watanabe-AIC[^waic], is a more fully Bayesian approach.  Under some conditions, the DIC and WAIC measures are asymptotically equivalent to Bayesian leave-one-out cross validation, as the AIC is under the classical setting.

### Posterior Predictive Checking: Statistical

For an overall assessment of model fit, we can examine how well the model can reproduce the data at hand given the $\theta$ draws from the posterior.  We discussed earlier the <span class="emph">posterior predictive distribution</span> for a future observation $\tilde{y}$, $p(\tilde{y}|y) = \int p(\tilde{y}|\theta)p(\theta|y)\mathrm{d}\theta$, and here we'll dive in to using it explicitly. There are two sources of uncertainty in our regression model, the variance $\sigma^2$ in y not explained by the model, and posterior uncertainty in the parameters due to having a finite sample size.  As $N\rightarrow\infty$, the latter goes to zero, and so we can simulate draws of $\tilde{y} \sim N(\tilde{X}\beta, \sigma^2I)$[^conjugate]. If $\tilde{X}$ is the model data as in the following, then we will refer to $y^{\textrm{Rep}}$ instead of $\tilde{y}$.

For our model this entails extracting the simulated values from the model object, and taking a random draw from the normal distribution based on the $\beta$ and $\sigma$ that are drawn to produce our <span class="emph">replicated data</span>, $y^{\textrm{Rep}}$ (see @gelman_bda, Appendix C).

```{r posteriorPredictiveExample, eval=TRUE, message=FALSE, fig.show='hide', echo=6:14}
load('data/mainModels.RData')
library(rstan)

# extract the simulated draws from the posterior and note the number for nsims
theta = extract(fit)
betas = theta$beta
sigmas = theta$sigma
nsims = length(theta$sigma)

# produce the replications and inspect
yRep = sapply(1:nsims, function(s) rnorm(250, X%*%betas[s,], sigmas[s]))
str(yRep)
```

With the $y^{\textrm{Rep}}$ in hand we can calculate all manner of statistics that might be of interest[^yrep]. 

As a starting point, we can check our minimum value among the replicated data sets versus that observed in the data.

```{r posteriorPredictiveMinComparison, eval=TRUE, warning=FALSE, message=FALSE, fig.keep='none', fig.show='hide', echo=1:7}
min_rep = apply(yRep, 2, min)
min_y = min(y)
hist(min_rep, main=''); abline(v=min_y)
c(mean(min_rep), min_y)
prop.table(table(min_rep>min_y))
sort(y)[1:5]
```

```{r posteriorPredictiveMinComparisonHist, eval=FALSE, warning=FALSE, message=FALSE, echo=FALSE}
prop.table(table(min_rep>sort(y)[3]))
# pdf('img/histofyrepMinimum.pdf', paper='USr')
# hist(min_rep, main='', 'FD', yaxt='n', ylab='', border='gray50'); abline(v=min_y, col='gray50')
# dev.off()
qplot(x=min_rep) + 
  geom_histogram(fill=scales::alpha('#ff5503', .95), color='gray50') + 
  geom_vline(xintercept=min_y, color='gray50') + 
  lazerhawk::theme_trueMinimal() +
  theme(axis.title.x=element_text(color='gray25'),
        axis.title.y=element_text(color='gray25'),
        plot.background = element_rect(fill = "transparent",colour = NA))
ggsave('img/histofyrepMinimum.svg', bg='transparent')
```


<span class="marginnote"><span class="imgbigger"><img src="img/histofyrepMinimum.svg" style="display:block; margin: 0 auto;" width=50%></span></span>
These results suggest we may be having difficulty picking up the lower tail of the target variable, as our average minimum is notably higher than that seen in the data, and almost all our minimums are greater than the observed minimum ($p=.99$).  While in this case we know that assuming the normal distribution for our sampling distribution is appropriate, this might otherwise have given us pause for further consideration.  A possible solution would be to assume a $t$ distribution for the sampling distribution, which would have fatter tails and thus possibly be better able to handle extreme values. We'll show an example of this later.  In this case it is just that by chance one of the $y$ values is extreme relative to the others.

In general, we can devise a test statistic, $T_{\textrm{Rep}}$, and associated p-value to check any particular result of interest based on the simulated data.  The p-value in this context is simply the percentage of times the statistic of interest is equal to or more extreme than the statistic, $T_y$, calculated for the original data.  Thus p-values near 0 or 1 are indicative of areas where the model is falling short in some fashion. Sometimes $T_y$ may be based on the $\theta$ parameters being estimated, and thus you'd have a $T_y$ for every posterior draw. In such a case one might examine the scatterplot of $T_{\textrm{Rep}}$ vs. $T_y$, or examine a density plot of the difference between the two.  In short, this is an area where one can get creative.  However, it must be stressed that we are not trying to accept or reject a model hypothesis as in the frequentist setting- we're not going to throw a model out because of an extreme p-value in our posterior predictive check.  We are merely trying to understand the model's shortcomings as best we can, and make appropriate adjustments if applicable.  It is often the case that the model will still be good enough for practical purposes.


### Posterior Predictive Checking: Graphical

<span class="marginnote"><span class="imgbigger"><img src="img/posteriorPredictiveFittedvsObserved.svg" style="display:block; margin: 0 auto;" width=50%></span></span>
As there are any number of ways to do statistical posterior predictive checks, we have many options for graphical inspection as well.  As a starting point I show a graph of our average fitted value versus the observed data.  The average is over all posterior draws of $\theta$.

```{r posteriorPredictiveFitted, eval=FALSE, warning=FALSE, message=FALSE, echo=FALSE}
library(ggplot2); library(reshape2)
fits = sapply(1:nsims, function(s) X%*%betas[s,])
avgfits = rowMeans(fits)
ggplot(aes(x=y, y=avgfits), data=data.frame(y=y, avgfits=avgfits)) +
  geom_point(col='#FF5503', alpha=.75, size=3) +
  labs(x='Observed y', y='Expected y') +
  lazerhawk::theme_trueMinimal() +
  theme(axis.title.x=element_text(color='gray25'),
        axis.title.y=element_text(color='gray25'),
        plot.background = element_rect(fill = "transparent",colour = NA))
ggsave('img/posteriorPredictiveFittedvsObserved.svg', bg='transparent')
```


Next, I show density plots for a random sample of 20 of the replicated data sets along with that of the original data (shaded).  In general it looks like we're doing pretty well here. The subsequent figure displays the density plot for individual predictions for a single value of $y$ from our data.  While it looks like some predictions were low for that value, in general the model captures this particular value of the data decently.<span class="marginnote"><span class="imgbigger"><img src="img/yRepDensity.svg" style="display:block; margin: 0 auto;" width=50%></span></span>

```{r posteriorPredictiveIndividualy, eval=FALSE, warning=FALSE, message=FALSE, echo=FALSE}
yRepSample = yRep[,sample(1:nsims, 20)]
gdat = melt(yRepSample); colnames(gdat) = c('n', 'nsim', 'yRep')
ggplot(aes(x=yRep), data=gdat) +
  stat_density(aes(x=y), size=1, fill='gray90', data.frame(y=y)) +
  stat_density(aes(group=as.factor(nsim), color=as.factor(nsim)), 
               alpha=.75, show.legend=F, geom='line', position='dodge') +  
  labs(x='', y='') +
  lazerhawk::theme_trueMinimal() +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        plot.background = element_rect(fill = "transparent",colour = NA))
ggsave('img/yRepDensity.svg', bg='transparent')


# marginal distribution check for each y as in BDA 6.5
ggplot(aes(x=yRep), data=gdat) +
#   stat_density(aes(x=y), size=1, fill='gray90') +
  stat_density(aes(group=as.factor(n), color=as.factor(n)), 
               alpha=.5, show.legend=F, geom='line', position='dodge') +  
  geom_vline(aes(xintercept=quantile(y))) +
  labs(x='', y='') +
  lazerhawk::theme_trueMinimal() +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

# yq = round(seq(1,250, length=5)) # rough quantiles
# yq = c(50,125,200)
yRepSample = yRep[,sample(1:nsims, 200)]
yq = 125
gdat = melt(yRepSample[order(y),]); colnames(gdat) = c('n', 'nsim', 'yRep')
gdat = gdat[gdat$n%in%yq,]
ggplot(aes(x=yRep), data=gdat) +
  geom_vline(aes(xintercept=sort(y)[yq]), alpha=.5) +
  stat_density(aes(group=as.factor(n), color=as.factor(n)), 
               alpha=.85, show.legend=F, geom='line', position='dodge') +  
  labs(x='', y='') +
  lazerhawk::theme_trueMinimal() +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        plot.background = element_rect(fill = "transparent",colour = NA))

ggsave('img/posteriorPredictiveFittedY.svg', bg='transparent')
```


We can also examine residual plots of $y - E(y|X,\theta)$ as with standard analysis, shown as the final two figures for this section.  The first shows such *realized* residuals, so-called as they are based on a posterior draw of $\theta$ rather than point estimation of the parameters, versus the expected values from the model.  
<span class="marginnote"><span class="imgbigger"><img src="img/posteriorPredictiveFittedY.svg" style="display:block; margin: 0 auto;" width=50%></span></span>
The next plot shows the average residual against the average fitted value.  No discernible patterns are present, so we may conclude that the model is adequate in this regard.
<span class="marginnote"><span class="imgbigger"><img src="img/posteriorPredictiveResidualRaw.svg" style="display:block; margin: 0 auto;" width=50%></span></span>
<span class="marginnote"><span class="imgbigger"><img src="img/posteriorPredictiveResidualAvg.svg" style="display:block; margin: 0 auto;" width=50%></span><br>The two plots directly above replicate the figures in 6.11 in Gelman 2013.</span>

```{r posteriorPredictiveResiduals,  tidy=FALSE, eval=FALSE, warning=FALSE, message=FALSE, echo=FALSE}
# marginal distribution check for each y as in BDA 6.5
# library(ggplot2); library(reshape2)
fits = sapply(1:nsims, function(s) X%*%betas[s,])
realizedResids = sapply(1:nsims, function(s) rnorm(250, fits[,s], sigmas[s]) - fits[,s])
gdat = melt(realizedResids); colnames(gdat) = c('n', 'nsim', 'residual')
gdat$fit = melt(fits)[,'value']
gdat$minres = rep(apply(realizedResids, 1, min), 3000)
gdat$maxres = rep(apply(realizedResids, 1, max), 3000)

# plot 6.11a
ggplot(aes(x=fit, y=residual), data=gdat[1:250,]) +
#   geom_linerange(aes(ymin=minres, ymax=maxres), alpha=.1) + 
  geom_hline(aes(yintercept=0), col='darkred', alpha=.25) +
  geom_point(aes(ymin=minres, ymax=maxres), color='#FF5500', alpha=.85) + 
  scale_x_continuous(breaks=c(-3,0,3,6,9,12)) +
  labs(x='Expected y', y='Realized Residual') +
  lazerhawk::theme_trueMinimal() +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        plot.background = element_rect(fill = "transparent",colour = NA))

ggsave('img/posteriorPredictiveResidualRaw.svg', bg="transparent")


avgfits = rowMeans(fits)
residRep = sweep(yRep, 1, avgfits)
avgresidRep = rowMeans(yRep-fits)

# figure 6.11b
ggplot(aes(x=avgfits, y=avgresidRep), data=data.frame(avgfits, avgresidRep)) +
  geom_point(alpha=.85, color='#FF5500') +
  labs(x='Average Expected y', y='Average Realized Residual') +
  lazerhawk::theme_trueMinimal() +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        plot.background = element_rect(fill = "transparent",colour = NA))

ggsave('img/posteriorPredictiveResidualAvg.svg', bg="transparent")
```



## Summary

As with standard approaches, every model should be checked to see whether it holds up under scrutiny. The previous discussion suggests only a few ways one might go about checking whether the model is worthwhile, but this is a very flexible area where one can answer questions beyond model adequacy and well beyond what traditional models can tell us. Not only is this phase of analysis a necessity, one can use it to explore a vast array of potential questions the data presents, and maybe even answer a few.





[^targetdist]: Recall again that we are looking for convergence to a distribution, not a specific parameter.

[^mcerr]: This is the 'naive' estimate the <span class="pack">coda</span> package provides in its summary output.

[^ppcheck]: Gelman devotes an entire chapter to this topic to go along with examples of model checking throughout his text.  Much of this section follows that outline.

[^waic]: See [Gelman et al. (2013)](http://www.stat.columbia.edu/~gelman/research/published/waic_understand3.pdf) for a review and references. See [Vehtari & Gelman (2014)](http://www.stat.columbia.edu/~gelman/research/unpublished/waic_stan.pdf) for some more on WAIC, as well as the R package <span class="pack">loo</span>.

[^conjugate]: Technically, in the conjugate case the posterior predictive is t-distributed because of the uncertainty in the parameters, though it doesn't take much sample size for simple models to get to approximately normal. Conceptually, with $\hat{\beta}$ being our mean $\beta$ estimate from the posterior, this can be represented as: <br> $\tilde{y} \sim t(\tilde{X}\hat{\beta}, \sigma^2 + \textrm{parUnc}, \textrm{df}=N-k)$

[^yrep]: In many cases you might want to produce this in the generated quantities section of your Stan code, but doing so outside of it will keep the stanfit object smaller, which may be desirable.

<!--chapter:end:04_diagnostics.Rmd-->

# Model Enhancements

Enhancing and making adjustments to a model can often be straightforward in the Bayesian context, depending on what one wants to accomplish.  In other cases, some things may be possible that aren't readily available with standard approaches in the traditional setting.  The following shows a few brief examples to give an idea of the possibilities.



## Generating New Variables of Interest

We have already seen one way to get at new statistics of interest in the predictive model checking section.  I next show how to do so as part of the modeling process itself.  In Stan we can accomplish this via the generated quantities section.

A typical part of linear regression output is $R^2$, the amount of variance accounted for by the model.  To get this in Stan we just have to create the code necessary for the calculations, and place it within the generated quantities section.  I only show this part of the model code; everything we had before would remain the same.  For comparison I show the corresponding R code. There are a couple of ways to go about this, and I use some of Stan's matrix operations as one approach.

<!-- You ran this and saved the image as data/mainModelDatawithRsq.RData -->


```{r generatedQuantitiesRsq, eval=FALSE, echo=-c(1, 6:34, 46)}
stanmodelcodeRsq = "
.
.
.

data {                      // Data block
  int<lower=1> N;           // Sample size
  int<lower=1> K;           // Dimension of model matrix
  matrix [N, K] X;          // Model Matrix
  vector[N] y;              // Target variable
}

/* 
transformed data {          // Transformed data block. Not used presently.
} 
*/

parameters {                // Parameters block; declarations only
  vector[K] beta;           // Coefficient vector
  real<lower=0> sigma;      // Error scale
}

model {                     // Model block
  vector[N] mu;
  mu <- X * beta;           // Creation of linear predictor
  
  // priors
  beta ~ normal(0, 10);
  sigma ~ cauchy(0, 5);     // With sigma bounded at 0, this is half-cauchy
  
  // likelihood
  y ~ normal(mu, sigma);
}

generated quantities {
  real rss;                
  real totalss;
  real<lower=0, upper=1> R2;                 
  vector[N] mu;
  
  mu <- X * beta;
  rss <- dot_self(y-mu);
  totalss <- dot_self(y-mean(y));
  R2 <- 1 - rss/totalss;
}
"
```

Using the results from the model using <span class="func">lm</span>, we do the same calculations for `rss` and `totalss`, and note the result is identical to what you'd see in the summary of the model.


```{r generatedQuantitiesvsR, eval=TRUE, cache=TRUE, echo=5}
load('data/mainModels.RData')
rss = crossprod(resid(modlm))
totalss = crossprod(y-mean(y))
rss = rss[1]; totalss = totalss[1] # for alignment, remove matrix
1-rss/totalss; summary(modlm)$r.squared
# 1-var(resid(modlm))/var(y) # alternatives
# var(fitted(modlm))/var(y)
```

Now we can run the model with added $R^2$.  Note that as before we do not just get a point estimate, but a whole distribution of simulated values for $R^2$.  First the results.




```{r generatedQuantitiesRsqResults, echo=-1}
load('data/mainModelDatawithRsq.RData')
print(fitRsq, digits=3, par=c('beta','sigma','R2'), prob=c(.025,.5,.975))
```

The nice thing here is that our $R^2$ incorporates the additional uncertainty in estimating the model parameters, and thus acts like an *adjusted* $R^2$[^adjr2].  The following is the classical regression adjusted $R^2$.


```{r generatedQuantitiesAdjRsq}
summary(modlm)$adj
```

Furthermore, in the Bayesian context we get an interval estimate and everything else we typically get as with other quantities of interest, and the same goes for anything we calculate along the way (e.g. the mu values). In addition, it would be trivial to calculate something like the actual adjusted $R^2$, the probability that the value is greater than .5, and other things of that nature.



## Robust Regression

If we were concerned that extreme observations exist that our current model is not able to capture well, we could change the sampling distribution to one that had a little more probability in the tails.  This is very easy to do in this situation, as we just change likelihood portion of our code to employ say, a t-distribution. In Stan, the t-distribution has parameters mean and sigma as with the normal distribution, but we also have the added parameter for degrees of freedom.  Thus our code might look like the following:


```{r robustRegressionT}
stanmodelcodeT = "
.
.
.

model {                     
  vector[N] mu;
  mu <- X * beta;           
  
  // priors
  beta ~ normal(0, 10);
  sigma ~ cauchy(0, 5);     
  
  // likelihood
  // y ~ normal(mu, sigma);            // previously used normal 
  y ~ student_t(10, mu, sigma)         // t with df=10
}
"
```

In this case we set the degrees of freedom at 10[^dfdat], but how would you know in advance what to set it as?  It might be better to place a prior (with lower bound of one) for that value and estimate it as part of the modeling process.  One should note that there are many distributions available in Stan (e.g. others might be useful for skewed data, truncated etc.), and more will be added in the future. 



## Generalized Linear Model

Expanding from standard linear model, we can move very easily to generalized linear models, of which the standard regression is a special case.  The key components are use of a link function that links the linear predictor to the target variable, and an appropriate sampling distribution for the likelihood.

Let's consider a count model using the Poisson distribution.  We can specify the model as follows:

$$y \sim Pois(\lambda)$$

$$g(\lambda) = X\beta$$


where $g(.)$ is the link function, the canonical link function for Poisson being the natural logarithm.  In Stan this can be expressed via the inverse link function, where we exponentiate the linear predictor.  Aside from that we simply specify $y$ as distributed Poisson in the same way we used the normal and t-distribution in earlier efforts.

```{r poissonRegression}
stanmodelcodePoisson = "
.
.
.

model {                     
  vector[N] lambda;
  vector[N] eta;

  eta <- X * beta;
  lambda <- exp(eta)
   
  // priors
  beta ~ normal(0, 10);

  // likelihood
  y ~ poisson(lambda)
}
"
```

And that's all there is to that[^stannotvec].  We just saw that we are not limited to the exponential family distributions of glm(s), though that covers a lot of ground, and so at this point you have a lot of the tools covered in standard applied statistics course, and a few beyond.


[^adjr2]: See [Gelman & Pardoe (2006)](http://www.stat.columbia.edu/~gelman/research/published/rsquared.pdf), Bayesian Measures of Explained Variance.

[^dfdat]: Alternatively, we could add a value 'df' to the data list and data block.

[^stannotvec]: Note that some link/inverse-link functions in Stan cannot be applied to vectors, only scalars.  As such you would have to loop over the values of $y$,<br> `for(n in 1:N) ...`

<!--chapter:end:05_enhancements.Rmd-->

# Issues

This section highlights some things to think about, as well as questions that would naturally arise for the applied researcher who might now be ready to start in on their first Bayesian analysis.  It provides merely a taste regarding some select issues, and at this point one should be consulting Bayesian analysis texts directly.


## Debugging

An essential part of Bayesian analysis is debugging to see if your code and model are doing what it should be doing[^debug], and this especially holds for more complex models.  For many models and common settings for the number of simulations, Bayesian analysis can still take several minutes on standard computers or laptops.  With big data and/or complex models, some might take hours or even *days*.  In either case, it is a waste of time to let broken code/models run unnecessarily.

The idea with debugging is that, once you think you have everything set up the way you like, run very short attempts to see if A, the code even compiles, and B, whether it runs appropriately.  As such, you will only want to set your warm-up and iterations to some small number to begin with, e.g. maybe not even 100 iterations, and no more than two chains[^compile].  Sometimes it will be obvious what a problem is, such as a typo resulting in the program of choice not being able to locate the parameter of interest.  Others may be fairly subtle, for example, when it comes to prior specification.

Along with shorter runs, one should consider simpler models first, and perhaps using only a subset of the data.  Especially for complex models, it helps to build the model up, debugging and checking for problems along the way.  As a not too complicated example, consider a mixed model for logistic regression.  One could even start with a standard linear model ignoring the binary nature of the target. Getting a sense of things from that and just making sure that inputs etc. are in place, one can supply the inverse logit link and change the sampling distribution to Bernoulli. Now you can think about adding the random effect, other explanatory variables of interest, and any other complexities that had not been included yet.

As you identify issues, you fix any problems that arise and tinker with other settings.  Once you are satisfied, *then* try for the big run.  Even then, you might spot new issues with a longer chain, so you can rinse and repeat at that point.  BUGS, JAGS, and Stan more or less have this capacity built in with model upgrade functions.  For example, in Stan you can feed the previous setup of a model in to the main <span class="func">stan</span> function.  Use one for your initial runs, then when you're ready, supply the model object as input to the 'fit' argument, perhaps with adjustments to the Monte Carlo settings.


## Choice of Prior

Selection of prior distributions might be a bit daunting for the new user of applied Bayesian analysis, but in many cases, and especially for standard models, there are more or less widely adopted choices.  Even so, we will discuss the options from a general point of view.

### Noninformative, Weakly Informative, Informative

We can begin with <span class="emph">noninformative priors</span> , which might also be referred to as *vague*, *flat*, *reference*, *objective*, or *diffuse*.  The idea is to use something that allows for Bayesian inference but puts all the premium on the data, and/or soi-disant *objectivity*.  As we have alluded to elsewhere, if we put a prior uniform distribution on the regression coefficients (and e.g. the log of $\sigma$), this would be a noninformative approach that would essentially be akin to maximum likelihood estimation.  One might wonder at this point why we wouldn't just use vague priors all the time and not worry about overly influencing the analysis by the choice of prior.

As an example, let's assume a uniform distribution $(-\infty,\infty)$ for some parameter $\theta$.  Without bounds, this prior is *improper*, i.e. the probability distribution does not integrate to 1.  While the posterior distribution may be proper, it is left the the researcher to determine this.  One also has to choose a suitable range, something which may not be easy to ascertain.  In addition, the distribution may not be uniform on some transformation of the parameter, say $\theta^2$.  A *Jeffreys' prior* could be used to overcome this particular issue, but is more difficult for multiparameter settings.

In general there are several issues with using a noninformative or reference prior.  For many models there may be no clear choice of what to use.  In any case, if the data are sufficient, the prior won't matter, so establishing some reference to be used automatically isn't exactly in keeping with Bayesian thinking. Furthermore, if you had clear prior information from previous research, one should use it.  Furthermore, such choices can still have unintended effects on the results.  In reality, any prior could be said to be <span class="emph">weakly informative</span>.

So instead of being completely ignorant, we can choose instead to be mostly ignorant, vague but not too vague.  As an example, consider our earlier [binomial distribution example](#prior-likelihood-posterior-distributions).  Perhaps a reasonable guess as to the probability of making a penalty was .75. With that as a basis, we could choose a Beta distribution that would have roughly 80%  of its probability between .6 and .9. We know that lower values for the parameters of a beta distribution represent a less informed state of mind, and the mean of the distribution is A/(A+B), so we could just fiddle with some values to see what we can turn up. The following code suggests a $\mathcal{B}(9,3)$ would probably be our best bet.  One can examine the distribution to the right. <span class="marginnote"><span class="imgbigger"><img src="img/betaDistr9and3.svg" style="display:block; margin: 0 auto;" width=50%></span></span>

```{r chooseBetaPrior, results='hold', echo=c(1:3), fig.keep='none'}
diff(pbeta(c(.6, .9), 3, 1))
diff(pbeta(c(.6, .9), 8, 3))
diff(pbeta(c(.6, .9), 9, 3))

# pdf('img/betaDistr2and6.pdf', paper='USr')
hist(rbeta(10000, 2, 6), border='gray50', col='#ff5503', xlab=expression(theta), breaks='FD')
# dev.off()
library(ggplot2)
ggplot(aes(x=x), data=data.frame(x=rbeta(10000, 9, 3))) + 
  geom_histogram(fill=scales::alpha('#ff5503', .95), color='gray50') + 
  lazerhawk::theme_trueMinimal() +
  theme(axis.title.x=element_text(color='gray25'),
        axis.title.y=element_text(color='gray25'),
        plot.background = element_rect(fill = "transparent",colour = NA))
ggsave('img/betaDistr9and3.svg', bg='transparent')
```

With our regression model we were dealing with standardized predictors, so even choosing a $\mathcal{N}(0, 10)$ might be overly vague, though it would be near flat from -1 to 1.  The nice part about setting the prior mean on zero is that it has a regularizing effect that can help avoid overfitting with smaller samples.

Thus weakly informative priors can be based on perfectly reasonable settings, and this probably makes more sense than claiming complete ignorance. Just some casual thought in many settings will often reveal that one isn't completely ignorant.  Furthermore if we have clear prior information, in the form of prior research for example, we can then use <span class="emph">informative</span> priors based on those results.  This again would be preferable to a completely noninformative approach.

### Conjugacy

Another consideration in the choice of prior is <span class="emph">conjugacy</span>.  Consider using the beta distribution as a prior for the binomial setting as we have done previously.  It turns out that using a $\beta(\mathcal{A}, \mathcal{B})$ results in the following posterior:

$$p(\theta|y, n) \propto \beta(y+\mathcal{A}, n-y+\mathcal{B})$$

Thus the posterior has the same parametric form as the prior, i.e. the beta distribution is *congugate* for the binomial likelihood.  In this sense, the prior has the interpretation as providing additional data points.  In our regression model, the conjugate setting uses a normal distribution for the predictor coefficients and an inverse gamma for $\sigma^2$.  In the case of exponential family distributions of generalized linear models, there are also natural conjugate prior distributions.

While there can be practical advantages to using a conjugate prior, it is not required, and for many more complex models, may not even be possible.  However it might help to consider a known conjugate prior as a starting point if nothing else.

### Sensitivity Analysis Revisited

As a reminder, we pointed out in the [sensitivity analysis][Sensitivity Analysis] section of the discussion on model checking, one may perform checks on settings for the model to see if changes to them results in gross changes of inference from the posterior.  Part of that check should include the choice of prior, whether different parameter values for the same distribution, or different distributions altogether. Doing such a check will give you more confidence in the final selection.


### Summary

<span class="marginnote">The BUGS book has many examples for a wide variety of applications.  The [Stan github page](https://github.com/stan-dev/example-models/wiki) has Stan examples for each of those BUGS examples and many more.</span>
It will not take long with a couple Bayesian texts or research articles that employ Bayesian methods to get a feel for how to go about choosing priors.  One should also remember that in the face of a lot of data, the likelihood will overwhelm the prior, rendering the choice effectively moot.  While the choice might be considered subjective in some respects, it is not arbitrary, and there are standard choices for common models and guidelines for more complex ones to help the researcher in their choice.



## Sampling Procedure

There are [many ways](http://m-clark.github.io/docs/ld_mcmc/) in which one might sample from the posterior.  Bayesian analysis is highly flexible and can solve a great many statistical models in theory.  In practice things can be more difficult.  As more complex models are attempted, new approaches are undertaken to deal with the problems in estimation that inevitably arise.  In an attempt to dissolve at least some of the mystery, a brief description follows.

### Metropolis

We have mentioned that BUGS and JAGS use <span class="emph">Gibbs sampling</span>, which is a special case of the <span class="emph">Metropolis-Hastings</span> (MH) algorithm[^MH], a very general approach encompassing a wide variety of techniques.  The Metropolis algorithm can be briefly described in the following steps:

1. Start with initial values for the parameters $\theta^0$


For $t=1,2...N_{sim}:$


2. Sample from some proposal distribution a potential candidate $\theta^*$, given $\theta^{t-1}$
3. Calculate the ratio $r$ of the posterior densities $\frac{p(\theta^*|y)}{p(\theta^{t-1}|y)}$ [^MHdifflog]
4. Set $\theta^t = \theta^*$ with probability $\min(r, 1)$, else  $\theta^t = \theta^{t-1}$


Conceptually, if the proposal increases the posterior density, $\theta^t = \theta^*$. If it decreases the proposal density, set $\theta^t = \theta^*$ with probability $r$, else it is $\theta^{t-1}$. The MH algorithm generalizes the Metropolis to use asymmetric proposal distributions and uses an $r$ to correct for asymmetry[^proposal]. 

Let's look at this in generic/pseudo R code for additional clarity:

```{r MHgeneric, eval=FALSE}
nsim = numberSimulatedDraws
theta0 = initValue
theta = c(theta0, rep(NA, nsim))

for (t in 2:nsim){
  thetaStar = rnorm(1, theta[-1], sd)
  u = runif(1)
  r = exp(logPosterior_thetaStar - logPosterior_theta0)
  theta[t] = ifelse(u<=r, thetaStar, theta[-1])
}
```

One can see the [Metropolis-Hastings Example](#MHexample) to see the Metropolis algorithm applied to our regression problem.


### Gibbs

The Gibbs sampler takes an alternating approach for multiparameter problems, sampling one parameter given the values of the others, and thus reducing a potentially high dimensional problem to lower dimensional conditional densities.   We can describe its steps generally as follows.

Start with initial values for some ordering of the parameters $\theta_1^0, \theta_2^0,..., \theta_p^0$

For $t=1,2..., N_{sim}:$

At iteration $t$, for $p=1,2..., P:$


- 1. $\theta_1^t \sim p(\theta_1^t | \theta_2^{t-1}, \theta_3^{t-1}, ..., \theta_p^{t-1})$
- 2.  Generate $\theta_2^t \sim p(\theta_2^t | \theta_1^{t}, \theta_3^{t-1}, ..., \theta_p^{t-1})$

- &nbsp;&nbsp;&nbsp;&nbsp; $\vdots$

- p. Generate $\theta_p^t \sim p(\theta_p^t | \theta_1^{t}, \theta_2^{t}, ..., \theta_{p-1}^{t})$

Again, some generic code may provide another way to understand it:

```{r Gibbsgeneric, eval=FALSE}
for (t in 1:nsim){
  for (p in 1:P){
    thetaNew[p] = rDistribution(1, theta[t,-p])
  }
  theta[t,] = thetaNew
}
```


### Hamiltonian Monte Carlo

Stan uses <span class="emph">Hamiltonian Monte Carlo</span>, another variant of MH. It takes the parameters $\theta$ as collectively denoting the position of a particle in some space with momentum $\phi$ (of same dimension as $\theta$). Both $\theta$ and $\phi$ are updated at each Metropolis step and jointly estimated, though we are only interested in $\theta$.  We can describe the basic steps as follows.


1. At iteration $t$, take a random draw of momentum $\phi$ from its posterior distribution
2. Update the position vector $\theta$ given current momentum, update $\phi$ given the gradient of $\theta$
3. Calculate $r = \frac{p(\theta^*|y)p(\phi^*)}{p(\theta^{t-1})p(\phi^{t-1})}$
4. Set $\theta^t = \theta^*$ with probability $min(r, 1)$, else  $\theta^t = \theta^{t-1}$



The overall process allows it to move quite rapidly through the parameter space, and it can work well where other approaches such as Gibbs might be very slow.  An example using HMC on the regression model data can be found in the [Hamiltonian Monte Carlo Example](#HMCexample)<label for="sn-demo" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-demo" class="margin-toggle"/><span class="sidenote">See this entry at David Mimno's blog for a [visualization of the process](http://www.mimno.org/articles/hmc/).</span>


### Other Variations and Approximate Methods

Within these MH approaches there are variations such as slice sampling, reversible jump, particle filtering, etc. Also, one can reparameterize the model to help overcome some convergence issues if applicable.  In addition, there exist many approximate methods such as Variational Bayes, INLA, Approximate Bayesian Computation, etc.  The main thing is just to be familiar with what's out there in case it might be useful.  Any particular method might be particularly well suited to certain models (e.g. INLA for spatial regression models), those that are notably complex, or they may just be convenient for a particular case.



## Number of draws, thinning, warm-up

Whatever program we use, the typical inputs that will need to be set regard the number of simulated draws from the posterior, the number of warm-up draws, and the amount of thinning.  Only the draws that remain after warm-up and thinning will be used for inference.  However, there certainly is no default that would work from one situation to the next.

Recall that we are looking for convergence to a distribution, and this isn't determined by the number of draws alone. The fact is that one only needs a few draws for accurate inference. Even something as low as $n_{\textrm{eff}}$ of 10 for each chain would actually be fine assuming everything else seemed in order, though typically we want more than that so that our values don't bounce around from one model run to the next.  To feel confident about convergence, i.e. get $\hat R$ of around 1, plots looking right, etc., we will usually want in the thousands for the number of total draws.  We might need quite a few more for increasing model complexity.

A conservative approach to the number of warm-up draws is half the number of runs, but this is fairly arbitrary. Thinning isn't specifically necessary for inference if approximate convergence is achieved, but is useful with increasing model complexity to reduce autocorrelation among the estimates.  

For myself, I typically run models such that the results are based on roughly $n_{\textrm{eff}} = 1000$ estimates per chain, simply because 1000 is a nice round number and is enough to make graphical display nice.  For a regression model as we have been running, that could be setting the number of simulations at 12000, the warm-up at 2000, and thinning at 10.  Other models might make due with 100000, 50000, 50 respectively.  You may just need to feel things out for yourself.


## Model Complexity
One of the great things about the Bayesian approach is its ability to handle extremely complex models involving lots of parameters.  In addition, it will often work better (or at all) in simpler settings where the data under consideration are problematic (e.g. collinearity, separation in the logistic regression setting).  While it can be quite an undertaking to set things correctly and debug, re-run etc. and generally go through the trial and error process typically associated with highly complex models, it's definitely nice to know that you can.  It will take some work, but you will also learn a great deal along the way.  Furthermore, there are typically tips and tricks that can potentially help just about any model run a little more smoothly.


[^debug]: It really should be a part of most analysis.

[^compile]: With Stan I sometimes do a 1 iteration compile check first.

[^MH]: Originally developed in physics in the 50s, it eventually made its way across to other fields.

[^MHdifflog]: In practice we can take the difference in the log values.

[^proposal]: Given a proposal/jumping distribution $\mathcal{J}_t$, <br>
$r=\frac{p(\theta^*|y)/\mathcal{J}_t(\theta^*|\theta^{t-1})} {p(\theta^{t-1}|y)/\mathcal{J}_t(\theta^{t-1}|\theta^*)}$

<!--chapter:end:06_issues.Rmd-->

# Summary

Hopefully this document has provided a path toward easing into Bayesian analysis for those that are interested but might not have had the confidence or particular skill set that many texts and courses assume.  Conceptually, Bayesian inference can be fairly straightforward, and inferentially is more akin to the ways people naturally think about probability.  Many of the steps taken in classical statistical analysis are still present, but have been enriched via the incorporation of prior information, a more flexible modeling scheme, and the ability to enhance even standard analyses with new means of investigation.

Of course it will not necessarily be easy, particularly for complex models, though such models might actually be relatively easier compared to the classical framework.  While not necessary for all models, oftentimes the process will involve a more hands-on approach.  However this allows for more understanding of the model and its results, and gets easier with practice just like anything else.

You certainly don't have to abandon classical and other methods either.  Scientific research involves applying the best tool for the job, and in some cases the Bayesian approach may not be the best fit for a particular problem.  But when it is, it's hoped you'll be willing to take the plunge, and know there are many tools and a great community of people to help you along the way.

<br>

<div style="text-align:center">Best of luck with your research!</div>

<!--chapter:end:1000_Conclusion.Rmd-->

# Appendix

NOTE EVAL AND CACHE FALSE UNTIL WE GET TO THIS SECTION. CHange back `startvals[1]` inline to r.

```{r temporary, include=FALSE}
knitr::opts_chunk$set(eval=T)
```

## Maximum Likelihood Review

This is a very brief refresher on <span class="emph">maximum likelihood estimation</span> using a standard regression approach as an example, and more or less assumes one hasn't tried to roll their own such function in a programming environment before.  Given the likelihood's role in Bayesian estimation and statistics in general, and the ties between specific Bayesian results and maximum likelihood estimates one typically comes across, I figure one should be comfortable with some basic likelihood estimation.

In the standard model setting we attempt to find parameters $\theta$ that will maximize the probability of the data we actually observe[^MLprinciple].  We'll start with an observed random target vector $y$ with $i...N$ independent and identically distributed observations and some data-generating process underlying it $f(\cdot|\theta)$.  We are interested in estimating the model parameter(s), $\theta$, that would make the data most likely to have occurred.  The probability density function for $y$ given some particular estimate for the parameters can be noted as $f(y_i|\theta)$.  The joint probability distribution of the (independent) observations given those parameters, $f(y_i|\theta)$, is the product of the individual densities, and is our *likelihood function*.  We can write it out generally as:
<span class='marginnote'><span class="imgbigger"><img src="img/maxLikeNormalCompareLLforDifferentMeans.svg" style="display:block; margin: 0 auto; width:90%"></span>


$$\mathcal{L}(\theta) = \prod_{i=1}^N f(y_i|\theta)$$


Thus the *likelihood* for one set of parameter estimates given a fixed set of data y, is equal to the probability of the data given those (fixed) estimates.  Furthermore we can compare one set, $\mathcal{L}(\theta_A)$, to that of another, $\mathcal{L}(\theta_B)$, and whichever produces the greater likelihood would be the preferred set of estimates.  We can get a sense of this with the graph to the right, based on a single parameter, Poisson distributed variable. The data is drawn from  a variable with mean $\theta=5$.  We note the calculated likelihood increases as we estimate values for $\theta$ closer to $5$.

```{r maxLikeillustration, cache=FALSE, eval=FALSE, echo=FALSE}
set.seed(1234)
y = rpois(100000, lambda=5)
mus = seq(3, 8, l=100)
L = sapply(mus, function(mu) sum(dpois(y, lambda=mu, log=T)))
mus[L==max(L)]

# y = rnorm(100000, mean=50, 10)
# mus = seq(40,60, l=100)
# L = sapply(mus, function(mu) sum(dnorm(y, mean=mu, sd=10, log=T)))

# y = rbinom(100000, size=100, p=.5)
# mus = seq(.3, .7, l=100)
# L = sapply(mus, function(mu) sum(dbinom(y, size=100, p=mu, log=T)))
# mus[L==max(L)]


library(ggplot2)
ggplot(data.frame(mus, L)) + 
  geom_vline(aes(xintercept=5), alpha=.5, lty=2) +
  geom_hline(aes(yintercept=max(L)), alpha=.5, lty=2) +
  geom_path(aes(x=mus, y=L), color='#ff5503', lwd=2) + 
  labs(x=expression(theta), y='Likelihood') +
  lazerhawk::theme_trueMinimal() +
  theme(axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.text.x=element_text(color='gray10', size=14),
        axis.title.x=element_text(color='gray10', size=24),
        plot.background = element_rect(fill = "transparent",colour = NA))
ggsave('img/maxLikeNormalCompareLLforDifferentMeans.svg', bg='transparent')
```



For computational reasons we instead work with the sum of the natural log probabilities[^logs], and thus the *log likelihood*:


$$\ln\mathcal{L}(\theta) = \sum_{i=1}^N \ln[f(y_i|\theta)]$$



Concretely, we calculate a log likelihood for each observation and then sum them for the total likelihood for parameter(s) $\theta$. 

The likelihood function incorporates our assumption about the sampling distribution of the data given some estimate for the parameters.  It can take on many forms and be notably complex depending on the model in question, but once specified, we can use any number of optimization approaches to find the estimates of the parameter that make the data most likely. As an example, for a normally distributed variable of interest we can write the log likelihood as follows:

$$\ln\mathcal{L}(\theta) = \sum_{i=1}^N \ln[\frac{1}{\sqrt{2\pi\sigma^2}}\exp(-\frac{(y-\mu)^2}{2\sigma^2})]$$


### Example

In the following we will demonstrate the maximum likelihood approach to estimation for a simple setting incorporating a normal distribution where we estimate the mean and variance/sd for a set of values $y$[^notlazy].  First the data is created, and then we create the function that will compute the log likelihood.  Using the built in R distributions[^distributions] makes it fairly straightforward to create our own likelihood function and feed it into an optimization function to find the best parameters.  We will set things up to work with the <span class="pack">bbmle</span> package, which has some nice summary functionality and other features.  However, one should take a glance at <span class="func">optim</span> and the other underlying functions that do the work.

```{r bblmDemo1, cache=F}
# for replication
set.seed(1234)

# create the data
y = rnorm(1000, mean=5, sd=2)
startvals = c(0, 1)

# the log likelihood function
LL = function(mu=startvals[1], sigma=startvals[2]){
  ll = -sum(dnorm(y, mean=mu, sd=sigma, log=T))
  message(paste(mu, sigma, ll))
  ll
}
```

The <span class="func">LL</span> function takes starting points for the parameters as arguments, in this case we call them $\mu$ and $\sigma$, which will be set to `startvals[1]` and `startvals[2]` respectively.  Only the first line (ll = -sum...) is actually necessary, and we use <span class="func">dnorm</span> to get the density for each point[^reasy].  Since this optimizer is by default minimization, we reverse the sign of the sum so as to minimize the negative log likelihood, which is the same as maximizing the likelihood.  Note that the bit of other code just allows you to see the estimates as the optimization procedure searches for the best values.  I do not show that here but you'll see it in your console.

We are now ready to obtain maximum likelihood estimates for the parameters.  For the <span class="func">mle2</span> function we will need the function we've created, plus other inputs related to that function or the underlying optimizing function used (by default <span class="func">optim</span>).  In this case we will use an optimization procedure that will allow us to set a lower bound for $\sigma$.  This isn't strictly necessary, but otherwise you would get get warnings and possibly lack of convergence if negative estimates for $\sigma$ were allowed[^logsigma]

```{r bblmDemo1B}
library(bbmle)
# using optim, and L-BFGS-B so as to contrain sigma to be positive by setting
# the lower bound at zero
mlnorm =  mle2(LL, method="L-BFGS-B", lower=c(sigma=0)) 
mlnorm

# compare to an intercept only regression model
summary(lm(y~1))
```

We can see that the ML estimates are the same[^MLvOLS] as the intercept only model estimates, which given the sample size are close to the true values.

In terms of the parameters we estimate, in the typical case of two or more parameters we can think of a <span class="emph">likelihood surface</span> that represents the possible likelihood values given any particular set of estimates. Given some starting point, the optimization procedure then travels along the surface looking for a minimum/maximum point[^tangent]. For simpler settings such as this, we can  visualize the likelihood surface and its minimum point. The optimizer travels along this surface until it finds a minimum.  I also plot the the path of the optimizer from a top down view.  The large blue dot noted represents the minimum negative log likelihood. 

<span class='marginnote'><span class="imgbigger"><img src="img/mlnorm.svg" style="display:block; margin: 0 auto;"> <br> A bit of jitter was added to the points to better see what's going on.</span>

<span class="imgbigger"><img src="img/mlnormLikelihoodSurface.svg" style="display:block; margin: 0 auto;">

Please note that there are many other considerations in optimization completely ignored here, but for our purposes and the audience for which this is intended, we do not want to lose sight of the forest for the trees. We now move next to a slightly more complicated regression example.



```{r plotSurface, eval=FALSE, echo=FALSE}
mu = seq(4, 6, length=50); sigma=seq(1.5, 3, length=50)
llsurf = matrix(NA, length(mu), length(sigma))

for (i in 1:length(mu)){
  for (j in 1:length(sigma)){
    llsurf[i,j] = -sum(dnorm(y, mean=mu[i], sd=sigma[j], log=T))
  }
}
rownames(llsurf) = mu
colnames(llsurf) = sigma
# llsurf
# # contour(llsurf)
# png('img/mlnormLikelihoodSurface.png', bg='transparent')
svg('img/mlnormLikelihoodSurface.svg', bg='transparent')
library(plot3D)
plotdat = read.csv('data//mleNormEstimates.csv'); colnames(plotdat) = c('mu','sigma', 'll')
pointdat = subset(plotdat, mu <=6 & mu >=4 & sigma<= 3 & sigma >=1.5)

# note that on col key, placement of legend (dist) will not match doc result so you'll have to play with it.
persp3D(x=mu, y=sigma, llsurf, zlim=c(2000, 2454),
        xlab='mu', ylab='sigma', zlab='neg ll', cex.lab=.75, cex.axis=.5, col.axis='gray50',  
        col=heat.colors(prod(dim(llsurf))), shade=.1, box=T, alpha=.75,
        contour=list(col=heat.colors(prod(dim(llsurf))), nlevels=20), addbox=F,
        phi=30, 
        ticktype='detailed', nticks=5, bty='u', tck=1, 
        colkey=list(col.box='white', cex.axis=.7, col.ticks=NA,  length=.75, width=.75)) -> res    ####### see this !
points(trans3d(pointdat[,1], pointdat[,2], pointdat[,3], pmat=res), pch=19, cex=.8, col=scales::alpha('gray',.5))
points(trans3d(coef(mlnorm)[1], coef(mlnorm)[2], mlnorm@min, pmat=res), pch=19, col=scales::alpha('navy',.85), cex=2)
dev.off()


### alternate via surface
# pdf('img/mlnormLikelihoodSurface2.pdf')
# M = mesh(mu, sigma)
# llsurf = matrix(NA, length(mu), length(sigma))  
# for (i in 1:length(mu)){
#   for (j in 1:length(sigma)){
#     llsurf[i,j] = -sum(dnorm(y, mean=mu[i], sd=sigma[j], log=T))
#   }
# }
# below = 100
# # par(mar=c(5, 4, 4, 2) + 0.1)
# surf3D(x=M$x, y=M$y, z=llsurf, colvar=llsurf, 
#        xlab='mu', ylab='sigma', zlab='neg ll', cex.lab=.75, cex.axis=.7, tck=1,
#        col=heat.colors(prod(dim(llsurf))), shade=.1, box=T, 
#        r=5, phi=10, 
#        ticktype='detailed', nticks=5, col.axis='gray25', alpha=.5,
#        colkey=list(col.box='white', cex.axis=.7, col.ticks=NA,  length=.75, width=.75), contour=T) 
# contour3D(mu, sigma, z=min(llsurf)-below, colvar=llsurf, col=heat.colors(prod(dim(llsurf))), add=T,
#           colkey=F, nlevels=20, dDepth=5, addbox=F) -> contourres
# points(trans3d(pointdat[,1], pointdat[,2], min(llsurf)-below, pmat=contourres), pch=19, cex=.8, col=scales::alpha('gray',.5))
# # lines(trans3d(pointdat[,1], pointdat[,2], min(llsurf)-100, pmat=contourres), pch=19, cex=.8, col=scales::alpha('gray',.5))
# points(trans3d(coef(mlnorm)[1], coef(mlnorm)[2], min(llsurf)-below, pmat=contourres), pch=19, col=scales::alpha('navy',.85), cex=2)
# points(trans3d(coef(mlnorm)[1], coef(mlnorm)[2], min(llsurf), pmat=contourres), pch=19, col=scales::alpha('navy',.85), cex=2)
# dev.off()
```

```{r plotNormMLEpath, cache=F, message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}
plotdat = read.csv('data//mleNormEstimates.csv'); colnames(plotdat) = c('mu','sigma', 'll')
plotdat$nll = -plotdat$ll

# car::scatter3d(ll~mu + sigma, data=plotdat, fill=F, grid=F, residuals=F, point.col='#FF5500')

library(ggplot2); library(reshape2)
ggplot(aes(x=mu, y=sigma), data=plotdat) + 
  geom_point(aes(), size=4, alpha=.15, show.legend=F, position = position_jitter(w = 0.2, h = 0.2)) +
  scale_size_continuous(range=c(.1,5)) +
  geom_point(aes(), col='navy', data=data.frame(t(coef(mlnorm))), size=10, alpha=1) + 
  # geom_path(aes(), col='navy', alpha=.5) +
  labs(x=expression(mu), y=expression(sigma))+
  lazerhawk::theme_trueMinimal() +
  theme(axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.text.x=element_text(color='gray10', size=14),
        axis.title.x=element_text(color='gray10', size=24),
        axis.title.y=element_text(color='gray10', size=24),
        plot.background = element_rect(fill = "transparent",colour = NA))
ggsave('img/mlnorm.svg', bg='transparent')
```

## Linear Model

In the standard regression context, our expected value for the target comes from our linear predictor, i.e. the weighted combination of our explanatory variables, and we estimate the regression weights/coefficients and possibly other relevant parameters.  We can expand our previous example to the standard linear model without too much change.  In this case we estimate a mean for each observation, but otherwise assume the variance is constant across observations.  Again we first construct some data so that we know exactly what to expect, then write out the likelihood function with starting parameters.  As we need to estimate our intercept and  coefficient for the X predictor (collectively referred to as $\beta$), we can can think of our likelihood  explicitly as before:

$$\ln\mathcal{L}(\beta, \sigma^2) = \sum_{i=1}^N \ln[\frac{1}{\sqrt{2\pi\sigma^2}}\exp(-\frac{(y-X\beta)^2}{2\sigma^2})]$$


```{r bblmeReg}
# for replication
set.seed(1234)

# predictor
X = rnorm(1000)

# coefficients for intercept and predictor
theta = c(5,2) 

# add intercept to X and create y with some noise
y = cbind(1,X)%*%theta + rnorm(1000, sd=2.5)

regLL = function(sigma=1, Int=0, b1=0){
  coefs = c(Int, b1)
  mu = cbind(1,X)%*%coefs
  ll = -sum(dnorm(y, mean=mu, sd=sigma, log=T))
  
  message(paste(sigma, Int, b1, ll))
  ll
}

library(bbmle)
mlopt =  mle2(regLL, method="L-BFGS-B", lower=c(sigma=0)) 
summary(mlopt)
# plot(profile(mlopt), absVal=F)

modlm = lm(y~X)
summary(modlm)
-2*logLik(modlm)
```

<span class='marginnote'><span class="imgbigger"><img src="img/mlreg.svg" style="display:block; margin: 0 auto;"></span>

As before, our estimates and final log likelihood value are about where they should be, and reflect the lm output.  The visualization becomes more difficult, but we can examine slices similar to the previous plot. 

To move to generalized linear models, very little changes of the process outside of the distribution assumed and that we are typically modeling a function of the target variable (e.g. $\log(y)=X\beta; mu = e^{X\beta}$).

```{r mlmisc, eval=FALSE, echo=FALSE}
plotdat = read.csv('data//mleEstimates.csv'); colnames(plotdat) = c('sigma', 'Intercept', 'beta_x', 'll')
# plotdat = read.csv('data//mleEstimates.csv'); colnames(plotdat) = c('sigma', 'Int', 'b1', 'll')
plotdat$nll = -plotdat$ll
# scatter3d(ll~sigma+b1, data=plotdat, fill=F, grid=F, fit='additive')


gdat= melt(plotdat, id=c('sigma', 'll', 'nll'))
ggplot(aes(x=sigma, y=value), data=gdat) + 
  geom_point(aes(size=nll), alpha=.15, show.legend=F, position = position_jitter(w = 0.2, h = 0.2)) +
  facet_wrap(~variable) +
#   geom_point(aes(y=b1, color=ll, size=-ll), alpha=.5) +
  scale_size_continuous(range=c(.5,5)) +
#   scale_color_continuous(limits=c(2310,5000)) +
#   geom_tile(aes(fill=ll)) +
#   scale_fill_gradient(low='red1', high='white', limits=c(2314, 2360), na.value='white') +
#   geom_point(aes(x=coef(mlopt)['Int'], y=coef(mlopt)['b1']), color='darkred', size=3) +
#   geom_point(aes(x=coef(mlopt)['sigma'], y=coef(mlopt)['b1']), color='darkred', size=3) +
#   geom_point(aes(x=coef(mlopt)['sigma'], y=coef(mlopt)['Int']), color='darkred', size=3) +
  labs(x=expression(sigma))+
  lazerhawk::theme_trueMinimal() +
  theme(axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.text.x=element_text(color='gray10', size=14),
        axis.title.x=element_text(color='gray10', size=24),
        plot.background = element_rect(fill = "transparent",colour = NA))
  
ggsave('img/mlreg.svg', bg='transparent')
```


## Binomial Likelihood Example

This regards the example seen in the early part of the document with the hands-on example.

```{r binomLL, echo=-1}
set.seed(1234)
x1 = rbinom(1000, size=10, p=.5)
x2 = rbinom(1000, size=10, p=.85)

binomLL = function(theta, x) {
  -sum(dbinom(x, size=10, p=theta, log=T))
}

optimize(binomLL, x=x1, lower=0, upper=1); mean(x1)
optimize(binomLL, x=x2, lower=0, upper=1); mean(x2)
```



## Modeling Languages

I will talk only briefly about a couple of the modeling language options available, as you will have to make your own choice among many.

### Bugs

BUGS [@bugsbook] (*B*ayesian inference *U*sing *G*ibbs *S*ampling) is perhaps the most widely known and used Bayesian modeling language, as it has been around for 25 years at this point.  It is implemented via [OpenBUGS](http://www.openbugs.net/) and freely available for download[^winbugs]. It even has a GUI interface if such a thing is desired.

### JAGS

[JAGS](http://mcmc-jags.sourceforge.net/) (*J*ust *A*nother *G*ibbs *S*ampler) is a more recent dialect of the BUGS language, and is also free to download.  It offers some technical and modeling advantages to OpenBUGs, but much of the code translates directly from one to the other.

### Stan

[Stan](http://mc-stan.org/) is a relative newcomer to Bayesian modeling languages, having only been out a couple years now.  It uses a different estimation procedure than the BUGS language and this makes it more flexible and perhaps better behaved for many types of models.  It actually compiles Stan code to C++, and so can be very fast as well.  I personally prefer it as I find it more clear in its expression, but your mileage may vary.


### R

R has many modeling packages devoted to Bayesian analysis such that there is a [Task View](http://cran.r-project.org/web/views/Bayesian.html) specific to the topic.  Most of them are even specific to the implementation of a certain type of analysis[^rbayes].  So not only can you do everything within R and take advantage of the power of those languages, you can then use Bayesian specific R packages on the results.  For standard and even some complex models I would suggest using the <span class="pack">rstanarm</span> or <span class="pack">brms</span> packages as a way to stick to the usual R modeling style, unless you have a notably complicated model, at wich point you can use <span class="pack">rstan</span>.


### General Statistical Packages

The general statistical languages such as SAS, SPSS, and Stata were generally very late to the Bayesian game, even for implementations of Bayesian versions of commonly used models.  SAS started a few years ago (roughly 2006) with experimental and extremely limited capability, and Stata only very recently (but there is [StataStan](http://mc-stan.org/interfaces/stata-stan)).  SPSS doesn't seem to have much capability in this area, much like a lot of other things.  Others still seem to be lacking as well.  In general, I wouldn't recommend these packages except as an interface to one of the Bayesian specific languages, assuming they have the capability.

### Other Programming Languages

Python has functionality via modules such as PyMC, and Stan has a Python implementation, PyStan.  Julia has some functionality similar in implementation to Matlab's, which one may also consider, and both have Stan ports as well.  And with any programming language that you might use for statistical analysis, you could certainly do a lot of it by hand if you have the time.

### Summary

In short, you have plenty of options.  I would suggest starting with a Bayesian programming language or using that language within your chosen statistical environment or package.  This gives you the most modeling flexibility, choice, and opportunity to learn.



## BUGS Example

The following provides a BUGS example of the primary model used in the document. The applicable code for the data set up is in the [Example: Linear Regression Model](#StanLMExample) section of the document. The model matrix X must be a matrix class object. Next we setup a bugs data list as we did with Stan, and create a text file that contains the model code.  Note that the data list comprises simple characters which are used to look for objects of those names that are in the environment. Also, I use <span class="func">cat</span> with <span class="func">sink</span> so that I don't have to go to a separate text editor to create the file.  

One of the big differences between BUGS and other languages is its use of the precision parameter $\frac{1}{\sigma^2}$, the inverse variance, usually denoted as $\tau$.  While there were some computational niceties to be had in doing so, even the authors admit this was not a good decision in retrospect. Prepare to have that issue come up from time to time when you inevitably forget.  Comments and assignments are the same as R, and distributions noted with $\sim$.

```{r bugsExampleDataSetup, eval=FALSE, echo=FALSE}
# set seed for replicability
set.seed(8675309)

# create a Nxk matrix of covariates
N = 250
K = 4

covariates = replicate(K-1, rnorm(n=N))

# create the model matrix with intercept
X = data.frame(Intercept=1, covariates)

# create a normally distributed target variable that is a function of the covariates
mu = with(X, 5 + .2*X1 - 1.5*X2 + .9*X3)
sigma = 2
y <- rnorm(N, mu, sigma)

# for comparison
modlm = lm(y~., X[,-1])

# Convert X to matrix for use with R2OpenBUGS
X = as.matrix(X)
```


```{r bugsBugsCodeSetup, eval=FALSE}
##################
### BUGS setup ###
##################

bugsdat = list('y', 'X', 'N', 'K')

# This will create a file, lmbugs.txt that will subsequently be called 
sink('data/lmbugs.txt')
cat(
'model {
  for (n in 1:N){
    mu[n] <- beta[1]*X[n,1] + beta[2]*X[n,2] + beta[3]*X[n,3] + beta[4]*X[n,4]
    y[n] ~ dnorm(mu[n], inv.sigma.sq)
  }
  for (k in 1:K){
    beta[k] ~ dnorm(0, .001) # prior for reg coefs
  }
  # Half-cauchy as in Gelman 2006
  # Scale parameter is 5, so precision of z = 1/5^2 = 0.04
  sigma.y <- abs(z)/sqrt(chSq) # prior for sigma; cauchy = normal/sqrt(chi^2)
  z ~ dnorm(0, .04)I(0,)
  chSq ~ dgamma(0.5, 0.5) # chi^2 with 1 d.f.
  inv.sigma.sq <- pow(sigma.y, -2) # precision
  # sigma.y ~ dgamma(.001, .001) # prior for sigma; a typical approach used.
}'
)
sink()

# explicitly provided initial values not necessary, but one can specify them  
# as follows, and you may have problems with variance parameters if you don't. 
# Note also that sigma.y is unnecesary if using the half-cauchy approach as  
# it is defined based on other values.

# inits <- list(list(beta=rep(0,4), sigma.y=runif(1,0,10)),
#               list(beta=rep(0,4), sigma.y=runif(1,0,10)),
#               list(beta=rep(0,4), sigma.y=runif(1,0,10)))
# parameters <- c('beta', 'sigma.y')
```

Now we are ready to run the model.  You'll want to examine the help file for the <span class="func">bugs</span> function for more information.  In addition, depending on your setup you may need to set the working directory and other options. Note that `n.thin` argument is used differently than other packages. One specifies the n posterior draws (per chain) you to keep want as n.iter-n.burnin. The thinned samples aren't stored. Compare this to other packages where n.iter is the total before thinning and including burn-in, and n.keep is (n.iter-n.burnin)/n.thin. With the function used here, n.keep is the same, but as far as arguments your you'll want to think of n.iter as the number of posterior draws *after* thinning. So the following all produce 1000 posterior draws in <span class="pack">R2OpenBUGS</span>:

```{r, kable, echo=FALSE, results='asis'}
tab = rbind(c("n.iter=3000,", "  n.thin=1,", "  n.burnin=2000"),
            c("n.iter=3000,", "  n.thin=10,", "  n.burnin=2000"),
            c("n.iter=3000,", "  n.thin=100,", "  n.burnin=2000"))
knitr::kable(tab, format='html')
```

In other packages, with those arguments you'd end up with 1000, 100, and 10 posterior draws.

```{r bugsRunModel, eval=FALSE, echo=-c(5, 9)}
#####################
### Run the model ###
#####################

library(R2OpenBUGS)
lmbugs <- bugs(bugsdat, inits=NULL, parameters=c('beta', 'sigma.y'), 
               model.file='lmbugs.txt', n.chains=3, n.iter=3000, n.thin=10, 
               n.burnin=2000)
# save.image('data/lmbugsResults.RData')
```

Now we are ready for the results, which will be the same as what we saw with Stan.  In addition to the usual output, you get the <span class="emph">deviance information criterion</span> as a potential means for model comparison.

```{r bugsModelResults, eval=c(1,3), echo=4, results='hold'}
load('data/lmbugsResults.RData')
print(lmbugs, digits=3)
round(lmbugs$summary[,c(1:3,5,7:9)], 3)
lmbugs$summary
```

The usual model diagnostics are available with conversion of the results to an object the \textcolor{blue}{coda} package can work with. Figures are not shown, but they are the typical traceplots and density plots.

```{r bugsModelDiag, eval=FALSE, echo=-c(1,7), fig.show='hide'}
library(coda); library(R2OpenBUGS)
lmbugscoda = as.mcmc.list(lmbugs)
traceplot(lmbugscoda)
densityplot(lmbugscoda)
plot(lmbugscoda)
corrplot:::corrplot(cor(lmbugscoda[[2]])) # noticeably better than levelplot
# par(mar=c(5, 4, 4, 2) + 0.1) # reset margins
```


## JAGS Example

The following shows how to run the regression model presented earlier in the document via JAGS. Once you have the data set up as before, the data list is done in the same fashion as with BUGS. The code itself is mostly identical, save for the use of T instead of I for truncation.  JAGS, being a BUGS dialect, also uses the precision parameter in lieu of the variance.


```{r jagsExample, eval=FALSE, echo=-1}
load('data/mainModelData.RData')
jagsdat = list('y'=y, 'X'=X, 'N'=N, 'K'=K)

sink('data/lmjags.txt')
cat(
'model {
  for (n in 1:N){
    mu[n] <- beta[1]*X[n,1] + beta[2]*X[n,2] + beta[3]*X[n,3] + beta[4]*X[n,4]
    y[n] ~ dnorm(mu[n], inv.sigma.sq)
  }
  
  for (k in 1:K){
    beta[k] ~ dnorm(0, .001)                               
  }
  
  # Half-cauchy as in Gelman 2006
  # Scale parameter is 5, so precision of z = 1/5^2 = 0.04
  sigma.y <- z/sqrt(chSq)       
  z ~ dnorm(0, .04)T(0,)
  chSq ~ dgamma(0.5, 0.5)                                  
  inv.sigma.sq <- pow(sigma.y, -2)                         
}'
)
sink()


# explicitly provided initial values not necessary, but can specify as follows
# inits <- function(){
#   list(beta=rep(0,4), sigma.y=runif(1,0,10))
# }
parameters <- c('beta', 'sigma.y')
```

With everything set, we can now run the model. With JAGS, we have what might be called an initialization stage that sets the model up and runs through the warm-up period, after which we can then flexibly sample from the posterior via the <span class="func">coda.samples</span> function.

```{r jagsRunModel, eval=FALSE, echo=-4}
library(rjags); library(coda)
lmjagsmod = jags.model(file='data/lmjags.txt', data=jagsdat, # inits=inits
                        n.chains=3, n.adapt=2000)
# update(lmjagsmod, 10000) # alternative approach
lmjags = coda.samples(lmjagsmod, c('beta', 'sigma.y'), n.iter=10000, 
                      thin=10, n.chains=3)
```

Now we have a model identical to the others, and can summarize the posterior distribution in similar fashion.

```{r jagsModelResults, echo=-1}
load('data/jagsModel.RData')
summary(lmjags)
coda::effectiveSize(lmjags)
```


```{r jagsModelDiag, eval=FALSE, echo=F}
# visualize
library(coda); library(scales); library(ggthemes)

traceplot(lmjags, col=alpha(gg_color_hue(3), .5))

densityplot(lmjags, col=alpha(gg_color_hue(3), .5))

plot(lmjags, col=alpha(gg_color_hue(3), .25))

corrplot:::corrplot(cor(lmjags[[2]]))  # noticeably better than levelplot
par(mar=c(5, 4, 4, 2) + 0.1) # reset margins
```





## Metropolis Hastings Example

Next depicted is a random walk Metropolis-Hastings algorithm using the the data and model from prior sections of the document.  I had several texts open while cobbling together this code such as @gelman_bda, and some oriented towards the social sciences by @jeff_gill_bayesian_2008, @simon_jackman_bayesian_2009, and @scott_lynch_2007 etc.  Some parts of the code reflect information and code examples found therein, and follows Lynch's code a bit more.

The primary functions that we need to specify regard the posterior distribution[^MHexample], an update step for beta coefficients, and an update step for the variance estimate.

<br>

```{r MHexample, cache=TRUE, eval=TRUE}
### posterior function
post = function(x, y, b, s2){
  # Args: X is the model matrix; y the target vector; b and s2 the parameters
  # to be esitmated

  beta = b           
  sigma = sqrt(s2)
  sigma2 = s2
  mu = X %*% beta
  
  # priors are b0 ~ N(0, sd=10), sigma2 ~ invGamma(.001, .001)
  priorbvarinv = diag(1/100, 4) 
  prioralpha = priorbeta = .001
  
  if(is.nan(sigma) | sigma<=0){     # scale parameter must be positive
    return(-Inf)
  }
  # Note that you will not find the exact same presentation across texts and 
  # other media for the log posterior in this conjugate setting.  In the end
  # they are conceputally still (log) prior + (log) likelihood
  else {                            
    -.5*nrow(X)*log(sigma2) - (.5*(1/sigma2) * (crossprod(y-mu))) +
      -.5*ncol(X)*log(sigma2) - (.5*(1/sigma2) * (t(beta)%*%priorbvarinv%*%beta)) + 
      -(prioralpha+1)*log(sigma2) + log(sigma2) - priorbeta/sigma2 
  }  
}

### update step for regression coefficients
updatereg = function(i, x, y, b, s2){
  # Args are the same as above but with additional i iterator argument.
  require(MASS)
  b[i,] = mvrnorm(1, mu=b[i-1,], Sigma=bvarscale)  # proposal/jumping distribution
  
  # Compare to past- does it increase the posterior probability?
  postdiff = post(x=x, y=y, b=b[i,],   s2=s2[i-1]) - 
             post(x=x, y=y, b=b[i-1,], s2=s2[i-1]) 
  
  # Acceptance phase
  unidraw = runif(1)
  accept = unidraw < min(exp(postdiff), 1)  # accept if so
  if(accept) b[i,]
  else b[i-1,]
}

# update step for sigma2
updates2 = function(i, x, y, b, s2){
  s2candidate =  rnorm(1, s2[i-1], sd=sigmascale)
  if(s2candidate < 0) {
    accept = FALSE
  } 
  else {
    s2diff = post(x=x, y=y, b=b[i,], s2=s2candidate) - 
             post(x=x, y=y, b=b[i,], s2=s2[i-1])
    unidraw = runif(1)
    accept = unidraw < min(exp(s2diff), 1)
  }
  
  ifelse(accept, s2candidate, s2[i-1])
}
```


Now we can set things up for the MCMC chain[^MHmcmc].  Aside from the typical MCMC setup and initializing the parameter matrices to hold the draws from the posterior, we also require scale parameters to use for the jumping/proposal distribution.

```{r MHexampleSetup, cache=TRUE, eval=TRUE}
### Setup, starting values etc. ###
nsim = 12000
burnin = 2000
thin = 10

b = matrix(0, nsim, ncol(X))         # initialize beta update matrix
s2 = rep(1, nsim)                    # initialize sigma vector


# For the following this c term comes from BDA3 12.2 and will produce an
# acceptance rate of .44 in 1 dimension and declining from there to about 
# .23 in high dimensions. For the sigmascale, the magic number comes from 
# starting with a value of one and fiddling from there to get around .44.
c = 2.4/sqrt(ncol(b))
bvar = vcov(lm(y~., data.frame(X[,-1]))) 
bvarscale = bvar * c^2               
sigmascale = .9
```

We can now run and summarize the model with tools from the <span class="pack">coda</span> package.

```{r MHexampleRun, cache=TRUE, eval=TRUE}
### Run ###
for(i in 2:nsim){
  b[i,] = updatereg(i=i, y=y, x=X, b=b, s2=s2)
  s2[i] = updates2(i=i, y=y, x=X, b=b, s2=s2)
}

# calculate acceptance rates; 
baccrate = mean(diff(b[(burnin+1):nsim,]) != 0)
s2accrate = mean(diff(s2[(burnin+1):nsim]) != 0)            
baccrate
s2accrate

# get final chain
library(coda)
bfinal = as.mcmc(b[seq(burnin+1, nsim, by=thin),])
s2final = as.mcmc(s2[seq(burnin+1, nsim, by=thin)])

# get summaries; compare to lm and stan
summary(bfinal); summary(s2final)
round(c(coef(modlm), summary(modlm)$sigma^2), 3)
```

Here is the previous Stan fit for comparison.

```{r MHexampleCompare, cache=TRUE, eval=TRUE}
print(fit, digits=3, prob=c(.025,.5,.975))
```



## Hamiltonian Monte Carlo Example


The following demonstrates Hamiltonian Monte Carlo, the technique that Stan uses, and which is a different estimation approach than Gibbs sampler in BUGS/JAGS.  It still assumes the data we used in this document, and is largely based on the code in the appendix of @gelman_bda.

First we start with the functions.

```{r HMCexample, cache=TRUE}
### Log posterior
log_p_th = function(X, y, th){
  # Args: X is the model matrix; y the target vector; th is the current 
  # parameter estimates.
  beta = th[-length(th)]            # reg coefs to be estimated
  sigma = th[length(th)]            # sigma to be estimated
  sigma2 = sigma^2
  mu = X %*% beta
  
  # priors are b0 ~ N(0, sd=10), sigma2 ~ invGamma(.001, .001)
  priorbvarinv = diag(1/100, 4) 
  prioralpha = priorbeta = .001
  
  if(is.nan(sigma) | sigma<=0){     # scale parameter must be positive, so post
    return(-Inf)                    # density is zero if it jumps below zero
  }
  # log posterior in this conjugate setting. Conceputally it's 
  # (log) prior + (log) likelihood.
  else {                            
    -.5*nrow(X)*log(sigma2) - (.5*(1/sigma2) * (crossprod(y-mu))) +
      -.5*ncol(X)*log(sigma2) - (.5*(1/sigma2) * (t(beta)%*%priorbvarinv%*%beta)) + 
      -(prioralpha+1)*log(sigma2) + log(sigma2) - priorbeta/sigma2 
  }  
}


### numerical gradient as given in BDA3 p. 602; same args as posterior
gradient_th_numerical = function(X, y, th){
  d = length(th)
  e = .0001
  diffs = numeric(5)
  for(k in 1:d){
    th_hi = th
    th_lo = th
    th_hi[k] = th[k] + e
    th_lo[k] = th[k] - e
    diffs[k] = (log_p_th(X, y, th_hi) - log_p_th(X, y, th_lo)) / (2*e)
  }
  return(diffs)
}


### single HMC iteration
hmc_iteration = function(X, y, th, epsilon, L, M){
  # Args: epsilon is the stepsize; L is the number of leapfrog steps; epsilon
  # and L are drawn randomly at each iteration to explore other areas of the
  # posterior (starting with epsilon0 and L0); M is a diagonal mass matrix 
  # (expressed as a vector), a bit of a magic number in this setting. It regards
  # the mass of a particle whose position is represented by theta, and momentum 
  # by phi. See the sampling section of chapter 1 in the Stan manual for more
  # detail.

  M_inv = 1/M
  d = length(th)
  phi = rnorm(d, 0, sqrt(M))
  th_old = th
  log_p_old = log_p_th(X, y, th) - .5*sum(M_inv*phi^2)
  phi = phi + .5*epsilon*gradient_th_numerical(X, y, th)
  
  for (l in 1:L){
    th = th + epsilon*M_inv*phi
    phi = phi + ifelse(l==L, .5, 1) * epsilon*gradient_th_numerical(X, y, th)
  }
  
  # here we get into standard MCMC stuff, jump or not based on a draw from a
  # proposal distribution
  phi = -phi
  log_p_star = log_p_th(X, y, th) - .5*sum(M_inv*phi^2)    
  r = exp(log_p_star - log_p_old)
  if (is.nan(r)) r = 0
  p_jump = min(r, 1)
  th_new = if(runif(1) < p_jump) th else th_old
  return(list(th=th_new, p_jump=p_jump))  # returns estimates and acceptance rate
}


### main HMC function
hmc_run = function(starts, iter, warmup, epsilon_0, L_0, M, X, y){
  # Args: starts are starting values; iter is total number of simulations for 
  # each chain (note chain is based on the dimension of starts); warmup
  # determines which of the initial iterations will be ignored for inference
  # purposes; edepsilon0 is the baseline stepsize; L0 is the baseline number 
  # of leapfrog steps; M is the mass vector
  chains = nrow(starts)
  d = ncol(starts)
  sims = array(NA, c(iter, chains, d), 
               dimnames=list(NULL, NULL, colnames(starts)))
  p_jump = matrix(NA, iter, chains)
  
  for(j in 1:chains){
    th = starts[j,]
    for(t in 1:iter){
      epsilon = runif(1, 0, 2*epsilon_0)
      L = ceiling(2*L_0*runif(1))
      temp = hmc_iteration(X, y, th, epsilon, L, M)
      p_jump[t,j] = temp$p_jump
      sims[t,j,] = temp$th
      th = temp$th
    }
  }
  
  rstan::monitor(sims, warmup, digits_summary=3)
  acc = round(colMeans(p_jump[(warmup+1):iter,]), 3)  # acceptance rate
  message('Avg acceptance probability for each chain: ', 
          paste0(acc[1],', ',acc[2]), '\n') 
  return(list(sims=sims, p_jump=p_jump))
}
```


With the primary functions in place, we set the starting values and choose other settings for for the HMC process. The coefficient starting values are based on random draws from a uniform distribution, while $\sigma$ is set to a value of one in each case.  As in the other examples we'll have 12000 total draws with warm-up set to 2000.  I don't have any thinning option but that could be added or simply done as part of the <span class="pack">coda</span> package preparation.

```{r HMCexampleSetup, cache=TRUE, echo=c(1:5, 7:16)}
### Starting values and mcmc settings
parnames = c(paste0('beta[',1:4,']'), 'sigma')
d = length(parnames)
chains = 2

load('data/mainModelData.RData')
thetastart = t(replicate(chains, c(runif(d-1, -1, 1), 1)))
colnames(thetastart) = parnames
nsim = 12000
wu = 2000

# fiddle with these to get a desirable acceptance rate of around .80. The
# following work well with the document data.
stepsize = .08
nLeap = 10
vars = rep(1, 5)
mass_vector = 1/vars
```


We are now ready to run the model.  On my machine and with the above settings, it took about two minutes. Once complete we can use the <span class="pack">coda</span> package if desired as we have done before.

```{r HMCexampleRun, cache=TRUE, message=T, eval=F}
### Run the model
M1 = hmc_run(starts=thetastart, iter=nsim, warmup=wu, epsilon_0=stepsize, 
             L_0=nLeap, M=mass_vector, X=X, y=y)
# str(M1, 1)

# use coda if desired
library(coda)

theta = as.mcmc.list(list(as.mcmc(M1$sims[(wu+1):nsim,1,]), 
                          as.mcmc(M1$sims[(wu+1):nsim,2,])))
# summary(theta)
finalest =  summary(theta)$statistics[,'Mean']
b = finalest[1:4]
sig = finalest[5]
log_p_th(X, y, finalest)
```

Our estimates look pretty good, and inspection of the diagnostics would show good mixing and convergence as well. At this point we can compare it to the Stan output.  For the following, I modified the previous Stan code to use the same inverse gamma prior and tweaked the control options for a little bit more similarity, but that's not necessary.


```{r HMCexampleStanCompare, cache=TRUE, eval=TRUE, echo=FALSE}
# Note: you ran and saved image to get around all the output being spit out.
### Stan
stanmodelcodeIG = "
data {                      // Data block
  int<lower=1> N;           // Sample size
  int<lower=1> K;           // Dimension of model matrix
  matrix [N, K] X;          // Model Matrix
  vector[N] y;              // Target variable
}

/* 
transformed data {          // Transformed data block. Not used presently.
} 
*/

parameters {                // Parameters block; declarations only
  vector[K] beta;           // Coefficient vector
  real<lower=0> sigma;      // Error scale
}

model {                     // Model block
  vector[N] mu;

  mu <- X * beta;           // Creation of linear predictor
  
  
  // priors
  beta ~ normal(0, 10);
  sigma ~ inv_gamma(.001, .001); // changed to gamma a la code above
  
  // likelihood
  y ~ normal(mu, sigma);
}

/*
generated quantities {      // Generated quantities block. Not used presently.
}
*/
"

dat = list(N=N, K=ncol(X), y=y, X=X)

# # standard stan
# fit = stan(model_code = stanmodelcodeIG, data = dat, iter = nsim, 
#            warmup=wu, thin=1, chains = chains, verbose = F)

# perhaps closer to above settings?
# fitIG = stan(model_code = stanmodelcodeIG, data = dat, iter = nsim, 
#            warmup=wu, thin=1, chains = chains, verbose = FALSE,
#            control=list(adap_engaged=F, stepsize=stepsize, adap_t0=nLeap, refresh=0))
load('data/IGModelData.RData')
print(fitIG, digits_summary=3, probs=c(.025,.5,.975))
# finalest; log_p_th(X, y, finalest)
```






[^MLprinciple]: The principle of maximum likelihood.

[^logs]: Math refresher on logs: `log(A*B) = log(A)+log(B)`. So summing the log probabilities will result in the same values for $\theta$, but won't result in extremely small values that will break our computer.

[^notlazy]: Of course we could just use the sample estimates, but this is for demonstration.

[^distributions]: Type `?Distributions` at the console for some of the basic R distributions available.

[^reasy]: Much more straightforward than writing the likelihood function as above.

[^logsigma]: An alternative approach would be to work with the log of $\sigma$ which can take on negative values, and then convert it back to the original scale.

[^MLvOLS]: Actually there is a difference between the sigma estimates in that OLS estimates are based on a variance estimate divided by $N-1$ while the MLE estimate has a divisor of $N$.

[^tangent]: Which is equivalent to finding the point where the slope of the tangent line to some function, i.e. the derivative, to the surface is zero. The derivative, or gradient in the case of multiple parameters, of the likelihood function with respect to the parameters is known as the <span class="emph">score function</span>.

[^winbugs]: You might come across a previous incarnation, WinBugs, but it is no longer being developed.

[^rbayes]: Many of these packages, if not all of them will be less flexible in model specification compared to implementing the aforementioned languages directly, or using the R interface to those languages.   What's more, R has interfaces to the previous language engines via the packages <span class="pack"></span>R2OpenBUGS</span> and <span class="pack"></span>BRugs</span>, <span class="pack"></span>rjags</span>, and <span class="pack">rstan</span>, <span class="pack">rstan_arm
brms</span>, and <span class=""></span>.

[^MHexample]: Assuming normal for $\beta$ coefficients, inverse gamma on $\sigma^2$.

[^MHmcmc]: This code regards only one chain, though a simple loop or any number of other approaches would easily extend it to two or more.

<!--chapter:end:1001_Appendix.Rmd-->

`r if (knitr:::is_html_output()) '# References {-}'`

## Texts

Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin, D. B. (2013). Bayesian Data
Analysis. 3rd edition.

Gill, J. (2008). *Bayesian methods : a social and behavioral sciences approach*. 2nd edition.

Jackman, S. (2009). *Bayesian analysis for the social sciences*. Wiley, Chichester, UK.

Kruschke, J. *Doing Bayesian Data Analysis*. Very intro book, but might be good for those not too confident in statistics generally speaking. And who doesn't like puppies? Second edition has Stan examples. (intro)

Lunn, D., Jackson, C., Best, N., Thomas, A., and Spiegelhalter, D. (2012). *The BUGS Book: A Practical
Introduction to Bayesian Analysis*. Chapman and Hall/CRC, Boca Raton, FL.

Lynch, S. M. (2007). Introduction to applied Bayesian statistics and estimation for social scientists. Springer,
New York.

McElreath, R. *Statistical Rethinking*.  A good modeling book in general, by one who has contributed a lot to helping others learn Stan.  Comes with its own R package too. (intro to moderate)



## Other

Statisticat, LLC. *Bayesian Inference*. A quick overview from the original author's of the <span class="pack">LaplacesDemon</span> package.

http://mc-stan.org/ Main website

http://stan.fit/ The Stan Group

More resources [here](http://mc-stan.org/documentation/)

<!--chapter:end:1002_references.Rmd-->

